{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "064d9ad9-113a-412a-880c-7d179549a2df",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9813ec-9d14-4abd-b35e-ba4329c7ba18",
   "metadata": {},
   "source": [
    "Use this page to get a full understand.\n",
    "https://cuijiahua.com/blog/2018/12/dl-10.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd7c533b-0d38-4a2c-8e78-eac71ac11776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "452a95b5-d436-4a19-9f65-8b393cc987f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1174e89a-981e-4ca1-9fc8-4386248bf3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "num_epochs = 5\n",
    "num_classes = 10\n",
    "batch_size = 100 # Total 100 batches\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf86ca88-7860-4d2a-b1c1-f64be4a04362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import os\n",
    "class MNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, train=True, transform=None):\n",
    "        # The file name prefix is obtained according to whether it is a training set or not.\n",
    "        self.file_pre = 'train' if train == True else 't10k'\n",
    "        self.transform = transform\n",
    "\n",
    "        # Generate the image and label file path of the corresponding dataset.\n",
    "        self.label_path = os.path.join(root, '%s-labels-idx1-ubyte.gz' % self.file_pre)\n",
    "        self.image_path = os.path.join(root, '%s-images-idx3-ubyte.gz' % self.file_pre)\n",
    "\n",
    "        # Read file data and return pictures and labels.\n",
    "        self.images, self.labels = self.__read_data__(self.image_path, self.label_path)\n",
    "\n",
    "    def __read_data__(self, image_path, label_path):\n",
    "        # Data set reading.\n",
    "        with gzip.open(label_path, 'rb') as lbpath:\n",
    "            labels = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "        with gzip.open(image_path, 'rb') as imgpath:\n",
    "            images = np.frombuffer(imgpath.read(), np.uint8, offset=16).reshape(len(labels), 28, 28)\n",
    "        return images, labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.images[index], int(self.labels[index])\n",
    "        \n",
    "        # If you need to convert to tensor, use tansform.\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(np.array(image))  # Avoid bug: use np.array\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb9e5633-4100-42d3-9c72-e838c3c6ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset (images and labels)\n",
    "# train_dataset = torchvision.datasets.MNIST(root='../data/MNIST', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "# test_dataset = torchvision.datasets.MNIST(root='../data/MNIST', train=False, transform=torchvision.transfroms.ToTensor(), download=True)\n",
    "# If datasets have been downloaded already!\n",
    "train_dataset = MNISTDataset('../data/MNIST/', transform=torchvision.transforms.ToTensor())\n",
    "test_dataset = MNISTDataset('../data/MNIST/', train=False, transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31ac0a0d-c0b1-4f78-824b-747cc17f370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9625ed31-86f5-48a8-b114-ce1081739b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the input parameters of the first full connection layer.\n",
    "def fc_in(image, Conv, Pool):\n",
    "    for i, j in zip(Conv, Pool):\n",
    "        hk = (image[0] - i[0] + 2 * i[2]) / i[1] + 1\n",
    "        wk = (image[1] - i[0] + 2 * i[2]) / i[1] + 1\n",
    "        hp = (hk - j[0] + 2 * j[2]) / j[1] + 1\n",
    "        wp = (wk - j[0] + 2 * j[2]) / j[1] + 1\n",
    "        image = (hp, wp)\n",
    "    return (int(image[0]), int(image[1]))\n",
    "fc_in((28, 28), ((5, 1, 2), (5, 1, 2)), ((2, 2, 0), (2, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d95696c-71b0-4cce-9c45-fabb737b247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network (two convolutional layers)\n",
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = torch.nn.Sequential(torch.nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "                                          torch.nn.BatchNorm2d(16),\n",
    "                                          torch.nn.ReLU(),\n",
    "                                          torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = torch.nn.Sequential(torch.nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "                                          torch.nn.BatchNorm2d(32),\n",
    "                                          torch.nn.ReLU(),\n",
    "                                          torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = torch.nn.Linear(7 * 7 * 32, num_classes)\n",
    "     \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        # out.size = (batchsize, channels, x, y)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38de1ec2-c6b6-43fa-97b4-cbf26bbf2a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make model\n",
    "model = ConvNet(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2779ff9-00e9-4e0a-8bf7-163b1feed523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbba036-85ac-43e5-bf93-62206e14bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a29d03-40d4-492e-a305-db2e42713d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "# Do not enable batchnormalization and dropout to ensure that BN and dropout do not change. The pytorch framework will automatically fix BN and dropout without averaging, but use the trained value.\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a74c01-47b3-47ba-a7fb-4b1e04494412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'cnn.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce01c0e-259e-4a15-8c5e-fb714ea014b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
