{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f3e570e-a522-4bd3-a516-f5ec309bc7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "287b257c-8fe4-49ad-bba0-86cb48b1e6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDetection:\n",
    "    \"\"\"\n",
    "    Class implements Yolo5 model to make inferences on a youtube video using Opencv2.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url, out_file=\"./data/VIDEOS/output/test1.mp4\"):\n",
    "        \"\"\"\n",
    "        Initializes the class with youtube url and output file.\n",
    "        :param url: Has to be as URL,on which prediction is made.\n",
    "        :param out_file: A valid output file name.\n",
    "        \"\"\"\n",
    "        self._URL = url\n",
    "        self.model = self.load_model()\n",
    "        self.classes = self.model.names\n",
    "        self.out_file = out_file\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    def get_video_from_url(self):\n",
    "        \"\"\"\n",
    "        Creates a new video streaming object to extract video frame by frame to make prediction on.\n",
    "        :return: opencv2 video capture object, with lowest quality frame available for video.\n",
    "        \"\"\"\n",
    "        # play = pafy.new(self._URL).streams[-1]\n",
    "        # assert play is not None\n",
    "        return cv2.VideoCapture(self._URL)\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"\n",
    "        Loads Yolo5 model from pytorch hub.\n",
    "        :return: Trained Pytorch model.\n",
    "        \"\"\"\n",
    "        model = torch.hub.load('ultralytics/yolov5', 'yolov5s', source='local', pretrained=True)\n",
    "        return model\n",
    "\n",
    "    def score_frame(self, frame):\n",
    "        \"\"\"\n",
    "        Takes a single frame as input, and scores the frame using yolo5 model.\n",
    "        :param frame: input frame in numpy/list/tuple format.\n",
    "        :return: Labels and Coordinates of objects detected by model in the frame.\n",
    "        \"\"\"\n",
    "        self.model.to(self.device)\n",
    "        frame = [frame]\n",
    "        results = self.model(frame)\n",
    "        labels, cord = results.xyxyn[0][:, -1].cpu().numpy(), results.xyxyn[0][:, :-1].cpu().numpy()\n",
    "        return labels, cord\n",
    "\n",
    "    def class_to_label(self, x):\n",
    "        \"\"\"\n",
    "        For a given label value, return corresponding string label.\n",
    "        :param x: numeric label\n",
    "        :return: corresponding string label\n",
    "        \"\"\"\n",
    "        return self.classes[int(x)]\n",
    "\n",
    "    def plot_boxes(self, results, frame, dicts):\n",
    "        \"\"\"\n",
    "        Takes a frame and its results as input, and plots the bounding boxes and label on to the frame.\n",
    "        :param results: contains labels and coordinates predicted by model on the given frame.\n",
    "        :param frame: Frame which has been scored.\n",
    "        :return: Frame with bounding boxes and labels ploted on it.\n",
    "        \"\"\"\n",
    "        import random\n",
    "        labels, cord = results\n",
    "        n = len(labels)\n",
    "        x_shape, y_shape = frame.shape[1], frame.shape[0]\n",
    "        for i in range(n):\n",
    "            row = cord[i]\n",
    "            if row[4] >= 0.2:\n",
    "                x1, y1, x2, y2 = int(row[0]*x_shape), int(row[1]*y_shape), int(row[2]*x_shape), int(row[3]*y_shape)\n",
    "                # Note the text color, make different text highlight the different color.\n",
    "                text = self.class_to_label(labels[i])\n",
    "                if(dicts.get(text) is not None):\n",
    "                    bgr = dicts[text]\n",
    "                else:\n",
    "                    bgr = [int(c) for c in list(np.random.choice(range(256), size=3))]\n",
    "                    dicts[text] = bgr\n",
    "                # bgr = (0, 255, 0)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), bgr, 2)\n",
    "                cv2.putText(frame, text, (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.9, bgr, 2)\n",
    "\n",
    "        return frame, dicts\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"\n",
    "        This function is called when class is executed, it runs the loop to read the video frame by frame,\n",
    "        and write the output into a new file.\n",
    "        :return: void\n",
    "        \"\"\"\n",
    "        d = {} # Define global dictionary\n",
    "        player = self.get_video_from_url()\n",
    "        assert player.isOpened()\n",
    "        x_shape = int(player.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        y_shape = int(player.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fourcc = cv2.VideoWriter_fourcc('M', 'P', '4', 'V')\n",
    "        out = cv2.VideoWriter(self.out_file, fourcc, 20, (x_shape, y_shape))\n",
    "        while True:\n",
    "            start_time = time()\n",
    "            ret, frame = player.read()\n",
    "            if ret:\n",
    "                cv2.namedWindow(\"frame\", 0)  # 0可调大小，注意：窗口名必须imshow里面的一窗口名一直\n",
    "                cv2.resizeWindow(\"frame\", 800, 450)\n",
    "                cv2.imshow('frame', frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    cv2.destroyWindow('frame')\n",
    "                    break\n",
    "                results = self.score_frame(frame)\n",
    "                frame, dicts = self.plot_boxes(results, frame, d)\n",
    "                d = dicts # Renew the dictionary\n",
    "                end_time = time()\n",
    "                fps = 1/np.round(end_time - start_time, 3)\n",
    "                # print(f\"Frames Per Second : {fps}\")\n",
    "                out.write(frame)\n",
    "            else:\n",
    "                cv2.destroyWindow('frame')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d61e0b3e-a85b-451b-aa76-30395e3be926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  320be46 torch 1.7.1+cu101 CUDA:0 (NVIDIA GeForce MX250, 2048MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# Create a new object and execute.\n",
    "a = ObjectDetection(\"data/VIDEOS/input/test.mp4\")\n",
    "a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3baba0a-11a0-4788-acf3-9421bb8d7e07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
