{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a0aae85-9b8e-402f-915e-78fab48df1d9",
   "metadata": {},
   "source": [
    "# Video Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c5494f-d5b8-4fda-8419-ae2bc7d5be98",
   "metadata": {},
   "source": [
    "## Load Dependent Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fe43cdc-5add-404e-80ed-92c708419419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1d4d45-2e51-451f-9545-3561a3cbfee5",
   "metadata": {},
   "source": [
    "## Design Detection Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287b257c-8fe4-49ad-bba0-86cb48b1e6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDetection:\n",
    "    \"\"\"\n",
    "    Class Implements YOLO5 Model to Make Inferences on A Local Video Using OpenCV2.\n",
    "    \"\"\"\n",
    "    def __init__(self, url: str, store: str=\"../data/VIDEOS/output/demo.mp4\"):\n",
    "        \"\"\"\n",
    "        Initialize the class with youtube url and output file.\n",
    "        :param url: must be as URL, on which prediction is made.\n",
    "        :param store: a valid output file path.\n",
    "        \"\"\"\n",
    "        self._URL = url\n",
    "        self.model = self.load_model() # load model\n",
    "        self.classes = self.model.names # classes of all objects\n",
    "        self.out_file = store\n",
    "        self.dict = {}\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu' # device configura\n",
    "\n",
    "    def get_video_from_url(self):\n",
    "        \"\"\"\n",
    "        Creates a new video streaming object to extract video frame by frame to make prediction on.\n",
    "        :return: opencv2 video capture object, with lowest quality frame available for video.\n",
    "        \"\"\"\n",
    "        return cv2.VideoCapture(self._URL)\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"\n",
    "        Loads yolo5 model from pytorch hub.\n",
    "        :return: trained pytorch model.\n",
    "        \"\"\"\n",
    "        model = torch.hub.load('../models/yolov5/', '../models/yolov5s.pt', source='local', pretrained=True)\n",
    "        return model\n",
    "\n",
    "    def score_frame(self, frame):\n",
    "        \"\"\"\n",
    "        Takes a single frame as input, and scores the frame using yolo5 model.\n",
    "        :param frame: input frame in numpy/list/tuple format.\n",
    "        :return: labels and coordinates of objects detected by model in the frame.\n",
    "        \"\"\"\n",
    "        self.model.to(self.device)\n",
    "        frame = [frame]\n",
    "        results = self.model(frame)\n",
    "        labels, cord = results.xyxyn[0][:, -1].cpu().numpy(), results.xyxyn[0][:, :-1].cpu().numpy()\n",
    "        return labels, cord\n",
    "\n",
    "    def class_to_label(self, x):\n",
    "        \"\"\"\n",
    "        For a given label value, return corresponding string label.\n",
    "        :param x: numeric label\n",
    "        :return: corresponding string label\n",
    "        \"\"\"\n",
    "        return self.classes[int(x)]\n",
    "\n",
    "    def plot_boxes(self, results, frame):\n",
    "        \"\"\"\n",
    "        Takes a frame and its results as input, and plots the bounding boxes and label on to the frame.\n",
    "        :param results: contains labels and coordinates predicted by model on the given frame.\n",
    "        :param frame: Frame which has been scored.\n",
    "        :return: frame with bounding boxes and labels ploted on it.\n",
    "        \"\"\"\n",
    "        labels, cord = results\n",
    "        n = len(labels)\n",
    "        x_shape, y_shape = frame.shape[1], frame.shape[0]\n",
    "        for i in range(n):\n",
    "            row = cord[i]\n",
    "            if row[4] >= 0.2:\n",
    "                x1, y1, x2, y2 = int(row[0]*x_shape), int(row[1]*y_shape), int(row[2]*x_shape), int(row[3]*y_shape)\n",
    "                # Note the text color, make different text highlight the different color.\n",
    "                text = self.class_to_label(labels[i])\n",
    "                if(self.dict.get(text) is not None):\n",
    "                    bgr = self.dict[text]\n",
    "                else:\n",
    "                    bgr = [int(c) for c in list(np.random.choice(range(256), size=3))]\n",
    "                    self.dict[text] = bgr\n",
    "                # bgr = (0, 255, 0)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), bgr, 2)\n",
    "                cv2.putText(frame, text, (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.9, bgr, 2)\n",
    "        return frame\n",
    "\n",
    "    def __call__(self) -> None:\n",
    "        \"\"\"\n",
    "        This function is called when class is executed, it runs the loop to read the video frame by frame,\n",
    "        and write the output into a new file.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        player = self.get_video_from_url()\n",
    "        assert player.isOpened()\n",
    "        x_shape = int(player.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        y_shape = int(player.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fourcc = cv2.VideoWriter_fourcc('M', 'P', '4', 'V')\n",
    "        out = cv2.VideoWriter(self.out_file, fourcc, 20, (x_shape, y_shape))\n",
    "        while True:\n",
    "            start_time = time()\n",
    "            ret, frame = player.read()\n",
    "            if ret:\n",
    "                cv2.namedWindow(\"frame\", 0)\n",
    "                cv2.resizeWindow(\"frame\", 800, 450)\n",
    "                cv2.imshow('frame', frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    cv2.destroyWindow('frame')\n",
    "                    break\n",
    "                results = self.score_frame(frame)\n",
    "                frame = self.plot_boxes(results, frame)\n",
    "                end_time = time()\n",
    "                fps = 1 / np.round(end_time - start_time, 3)\n",
    "                # print(f\"Frames Per Second : {fps}\")\n",
    "                out.write(frame)\n",
    "            else:\n",
    "                cv2.destroyWindow('frame')\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20b25f5-8acc-4f4a-8b61-0834cc77666d",
   "metadata": {},
   "source": [
    "## Create A New Object and Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a61a04-2cd8-4a02-8ed1-eb4f7f954f5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot find callable ../models/yolov5s.pt in hubconf",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32me:\\Self\\ongoing\\easy-pytorch\\notebooks\\video_detection.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Self/ongoing/easy-pytorch/notebooks/video_detection.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ob \u001b[39m=\u001b[39m ObjectDetection(\u001b[39m\"\u001b[39;49m\u001b[39m../data/VIDEOS/input/demo.mp4\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Self/ongoing/easy-pytorch/notebooks/video_detection.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m ob()\n",
      "\u001b[1;32me:\\Self\\ongoing\\easy-pytorch\\notebooks\\video_detection.ipynb Cell 7\u001b[0m in \u001b[0;36mObjectDetection.__init__\u001b[1;34m(self, url, store)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Self/ongoing/easy-pytorch/notebooks/video_detection.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Self/ongoing/easy-pytorch/notebooks/video_detection.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mInitialize the class with youtube url and output file.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Self/ongoing/easy-pytorch/notebooks/video_detection.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m:param url: must be as URL, on which prediction is made.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Self/ongoing/easy-pytorch/notebooks/video_detection.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m:param store: a valid output file path.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Self/ongoing/easy-pytorch/notebooks/video_detection.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Self/ongoing/easy-pytorch/notebooks/video_detection.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_URL \u001b[39m=\u001b[39m url\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Self/ongoing/easy-pytorch/notebooks/video_detection.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_model() \u001b[39m# load model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Self/ongoing/easy-pytorch/notebooks/video_detection.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mnames \u001b[39m# classes of all objects\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Self/ongoing/easy-pytorch/notebooks/video_detection.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_file \u001b[39m=\u001b[39m store\n",
      "\u001b[1;32me:\\Self\\ongoing\\easy-pytorch\\notebooks\\video_detection.ipynb Cell 7\u001b[0m in \u001b[0;36mObjectDetection.load_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Self/ongoing/easy-pytorch/notebooks/video_detection.ipynb#W6sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Self/ongoing/easy-pytorch/notebooks/video_detection.ipynb#W6sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Self/ongoing/easy-pytorch/notebooks/video_detection.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m    Loads yolo5 model from pytorch hub.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Self/ongoing/easy-pytorch/notebooks/video_detection.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m    :return: trained pytorch model.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Self/ongoing/easy-pytorch/notebooks/video_detection.ipynb#W6sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Self/ongoing/easy-pytorch/notebooks/video_detection.ipynb#W6sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mhub\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39m../models/yolov5/\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m../models/yolov5s.pt\u001b[39;49m\u001b[39m'\u001b[39;49m, source\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlocal\u001b[39;49m\u001b[39m'\u001b[39;49m, pretrained\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Self/ongoing/easy-pytorch/notebooks/video_detection.ipynb#W6sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\hub.py:370\u001b[0m, in \u001b[0;36mload\u001b[1;34m(repo_or_dir, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[39mif\u001b[39;00m source \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgithub\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    368\u001b[0m     repo_or_dir \u001b[39m=\u001b[39m _get_cache_or_reload(repo_or_dir, force_reload, verbose)\n\u001b[1;32m--> 370\u001b[0m model \u001b[39m=\u001b[39m _load_local(repo_or_dir, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    371\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\hub.py:398\u001b[0m, in \u001b[0;36m_load_local\u001b[1;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m hubconf_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(hubconf_dir, MODULE_HUBCONF)\n\u001b[0;32m    396\u001b[0m hub_module \u001b[39m=\u001b[39m import_module(MODULE_HUBCONF, hubconf_path)\n\u001b[1;32m--> 398\u001b[0m entry \u001b[39m=\u001b[39m _load_entry_from_hubconf(hub_module, model)\n\u001b[0;32m    399\u001b[0m model \u001b[39m=\u001b[39m entry(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    401\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mremove(hubconf_dir)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\hub.py:218\u001b[0m, in \u001b[0;36m_load_entry_from_hubconf\u001b[1;34m(m, model)\u001b[0m\n\u001b[0;32m    215\u001b[0m func \u001b[39m=\u001b[39m _load_attr_from_module(m, model)\n\u001b[0;32m    217\u001b[0m \u001b[39mif\u001b[39;00m func \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(func):\n\u001b[1;32m--> 218\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCannot find callable \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m in hubconf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(model))\n\u001b[0;32m    220\u001b[0m \u001b[39mreturn\u001b[39;00m func\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot find callable ../models/yolov5s.pt in hubconf"
     ]
    }
   ],
   "source": [
    "demo = ObjectDetection(\"../data/VIDEOS/input/demo.mp4\")\n",
    "demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3baba0a-11a0-4788-acf3-9421bb8d7e07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
