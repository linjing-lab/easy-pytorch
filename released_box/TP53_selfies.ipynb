{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>label</th><th>one_hot</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;CHEMBL179549&quot;</td><td>&quot;[24, 24, 24, 30, 24, 7, 24, 12…</td><td>&quot;[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0…</td></tr><tr><td>&quot;CHEMBL360920&quot;</td><td>&quot;[24, 24, 24, 30, 24, 7, 24, 12…</td><td>&quot;[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0…</td></tr><tr><td>&quot;CHEMBL182052&quot;</td><td>&quot;[24, 24, 24, 33, 24, 17, 8, 24…</td><td>&quot;[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0…</td></tr><tr><td>&quot;CHEMBL179662&quot;</td><td>&quot;[33, 24, 24, 18, 36, 24, 30, 2…</td><td>&quot;[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0…</td></tr><tr><td>&quot;CHEMBL181688&quot;</td><td>&quot;[24, 24, 17, 24, 24, 17, 24, 2…</td><td>&quot;[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌──────────────┬─────────────────────────────────┬─────────────────────────────────┐\n",
       "│ id           ┆ label                           ┆ one_hot                         │\n",
       "│ ---          ┆ ---                             ┆ ---                             │\n",
       "│ str          ┆ str                             ┆ str                             │\n",
       "╞══════════════╪═════════════════════════════════╪═════════════════════════════════╡\n",
       "│ CHEMBL179549 ┆ [24, 24, 24, 30, 24, 7, 24, 12… ┆ [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0… │\n",
       "│ CHEMBL360920 ┆ [24, 24, 24, 30, 24, 7, 24, 12… ┆ [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0… │\n",
       "│ CHEMBL182052 ┆ [24, 24, 24, 33, 24, 17, 8, 24… ┆ [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0… │\n",
       "│ CHEMBL179662 ┆ [33, 24, 24, 18, 36, 24, 30, 2… ┆ [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0… │\n",
       "│ CHEMBL181688 ┆ [24, 24, 17, 24, 24, 17, 24, 2… ┆ [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0… │\n",
       "└──────────────┴─────────────────────────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars\n",
    "import numpy\n",
    "df = polars.read_csv(\"descriptor_selfies.csv\", separator='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y= df[\"one_hot\"], df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_num = []\n",
    "for y_str in y:\n",
    "    y_list = eval(y_str)\n",
    "    y_num.append(y_list)\n",
    "y = numpy.array(y_num) # create multi-outputs labels\n",
    "del y_str, y_list, y_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = []\n",
    "for X_str in X:\n",
    "    X_list = eval(X_str)\n",
    "    X_flatten = [item for sublist in X_list for item in sublist]\n",
    "    X_num.append(X_flatten)\n",
    "X = numpy.array(X_num) # create flatten features\n",
    "del X_str, X_list, X_flatten, X_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1325, 8862), (1325, 211))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (Linear0): Linear(in_features=8862, out_features=3000, bias=True)\n",
      "    (Activation0): ReLU(inplace=True)\n",
      "    (Linear1): Linear(in_features=3000, out_features=211, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('torch -v', '1.7.1+cu101'),\n",
       "             ('criterion', MSELoss()),\n",
       "             ('batch_size', 64),\n",
       "             ('solver',\n",
       "              Adam (\n",
       "              Parameter Group 0\n",
       "                  amsgrad: False\n",
       "                  betas: (0.9, 0.99)\n",
       "                  eps: 1e-08\n",
       "                  lr: 0.01\n",
       "                  weight_decay: 0\n",
       "              )),\n",
       "             ('lr_scheduler', None),\n",
       "             ('device', device(type='cuda'))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import perming\n",
    "main = perming.Box(8862, 211, (3000,), batch_size=64, activation='relu', inplace_on=True, criterion='MSELoss', solver='adam', learning_rate_init=0.01)\n",
    "main.print_config() # extract features with main effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(\"float\") # multi-outputs\n",
    "main.data_loader(X, y, random_seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60], Step [10/17], Training Loss: 683.9639, Validation Loss: 158.5208\n",
      "Epoch [2/60], Step [10/17], Training Loss: 74.4517, Validation Loss: 16.8641\n",
      "Epoch [3/60], Step [10/17], Training Loss: 41.3552, Validation Loss: 13.4700\n",
      "Epoch [4/60], Step [10/17], Training Loss: 39.0044, Validation Loss: 13.0534\n",
      "Epoch [5/60], Step [10/17], Training Loss: 35.2509, Validation Loss: 11.4001\n",
      "Epoch [6/60], Step [10/17], Training Loss: 31.8014, Validation Loss: 10.8461\n",
      "Epoch [7/60], Step [10/17], Training Loss: 29.4561, Validation Loss: 9.9555\n",
      "Epoch [8/60], Step [10/17], Training Loss: 29.6944, Validation Loss: 8.6690\n",
      "Epoch [9/60], Step [10/17], Training Loss: 26.8422, Validation Loss: 9.0475\n",
      "Epoch [10/60], Step [10/17], Training Loss: 23.5534, Validation Loss: 8.4559\n",
      "Epoch [11/60], Step [10/17], Training Loss: 22.1152, Validation Loss: 7.9635\n",
      "Epoch [12/60], Step [10/17], Training Loss: 20.2078, Validation Loss: 7.2285\n",
      "Epoch [13/60], Step [10/17], Training Loss: 18.4414, Validation Loss: 6.6722\n",
      "Epoch [14/60], Step [10/17], Training Loss: 16.1690, Validation Loss: 6.1117\n",
      "Epoch [15/60], Step [10/17], Training Loss: 13.4766, Validation Loss: 5.5554\n",
      "Epoch [16/60], Step [10/17], Training Loss: 11.8005, Validation Loss: 5.1315\n",
      "Epoch [17/60], Step [10/17], Training Loss: 10.5361, Validation Loss: 4.5014\n",
      "Epoch [18/60], Step [10/17], Training Loss: 9.9437, Validation Loss: 3.5443\n",
      "Epoch [19/60], Step [10/17], Training Loss: 10.6306, Validation Loss: 3.9934\n",
      "Epoch [20/60], Step [10/17], Training Loss: 6.8944, Validation Loss: 3.4801\n",
      "Epoch [21/60], Step [10/17], Training Loss: 7.0011, Validation Loss: 3.2631\n",
      "Epoch [22/60], Step [10/17], Training Loss: 5.5973, Validation Loss: 2.2316\n",
      "Epoch [23/60], Step [10/17], Training Loss: 4.8216, Validation Loss: 2.8058\n",
      "Epoch [24/60], Step [10/17], Training Loss: 5.5661, Validation Loss: 2.7639\n",
      "Epoch [25/60], Step [10/17], Training Loss: 3.6590, Validation Loss: 1.7645\n",
      "Epoch [26/60], Step [10/17], Training Loss: 5.0497, Validation Loss: 2.5980\n",
      "Epoch [27/60], Step [10/17], Training Loss: 3.6462, Validation Loss: 2.3122\n",
      "Epoch [28/60], Step [10/17], Training Loss: 2.6290, Validation Loss: 1.4721\n",
      "Epoch [29/60], Step [10/17], Training Loss: 3.0749, Validation Loss: 1.4911\n",
      "Epoch [30/60], Step [10/17], Training Loss: 4.1072, Validation Loss: 2.2163\n",
      "Epoch [31/60], Step [10/17], Training Loss: 3.2650, Validation Loss: 1.3476\n",
      "Epoch [32/60], Step [10/17], Training Loss: 1.6862, Validation Loss: 2.0011\n",
      "Epoch [33/60], Step [10/17], Training Loss: 1.6189, Validation Loss: 1.9502\n",
      "Epoch [34/60], Step [10/17], Training Loss: 1.2636, Validation Loss: 1.8931\n",
      "Epoch [35/60], Step [10/17], Training Loss: 0.8869, Validation Loss: 1.6373\n",
      "Epoch [36/60], Step [10/17], Training Loss: 0.9195, Validation Loss: 1.7993\n",
      "Epoch [37/60], Step [10/17], Training Loss: 1.3679, Validation Loss: 1.0173\n",
      "Epoch [38/60], Step [10/17], Training Loss: 1.6105, Validation Loss: 1.1197\n",
      "Epoch [39/60], Step [10/17], Training Loss: 1.1611, Validation Loss: 1.1692\n",
      "Epoch [40/60], Step [10/17], Training Loss: 1.5315, Validation Loss: 1.2795\n",
      "Epoch [41/60], Step [10/17], Training Loss: 1.5300, Validation Loss: 1.8402\n",
      "Epoch [42/60], Step [10/17], Training Loss: 0.7957, Validation Loss: 1.1387\n",
      "Epoch [43/60], Step [10/17], Training Loss: 0.6859, Validation Loss: 1.8664\n",
      "Epoch [44/60], Step [10/17], Training Loss: 0.7019, Validation Loss: 1.7125\n",
      "Epoch [45/60], Step [10/17], Training Loss: 0.6334, Validation Loss: 1.4241\n",
      "Epoch [46/60], Step [10/17], Training Loss: 0.6721, Validation Loss: 1.6616\n",
      "Epoch [47/60], Step [10/17], Training Loss: 0.5243, Validation Loss: 0.9518\n",
      "Epoch [48/60], Step [10/17], Training Loss: 1.3168, Validation Loss: 1.6350\n",
      "Epoch [49/60], Step [10/17], Training Loss: 3.0425, Validation Loss: 1.6377\n",
      "Epoch [50/60], Step [10/17], Training Loss: 0.7838, Validation Loss: 1.0091\n",
      "Epoch [51/60], Step [10/17], Training Loss: 0.8132, Validation Loss: 0.9184\n",
      "Epoch [52/60], Step [10/17], Training Loss: 0.8691, Validation Loss: 1.3815\n",
      "Epoch [53/60], Step [10/17], Training Loss: 0.5132, Validation Loss: 1.3461\n",
      "Epoch [54/60], Step [10/17], Training Loss: 0.7782, Validation Loss: 1.6065\n",
      "Epoch [55/60], Step [10/17], Training Loss: 0.4455, Validation Loss: 1.3275\n",
      "Epoch [56/60], Step [10/17], Training Loss: 0.4325, Validation Loss: 0.9537\n",
      "Epoch [57/60], Step [10/17], Training Loss: 0.7526, Validation Loss: 1.2994\n",
      "Epoch [58/60], Step [10/17], Training Loss: 0.9250, Validation Loss: 0.9559\n",
      "Epoch [59/60], Step [10/17], Training Loss: 0.7086, Validation Loss: 0.8987\n",
      "Epoch [60/60], Step [10/17], Training Loss: 1.2652, Validation Loss: 1.5949\n"
     ]
    }
   ],
   "source": [
    "main.train_val(num_epochs=60, interval=10, backend='threading', prefer='threads', early_stop=True) # set n_jobs > 1 within number of processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of Box on the 192 test dataset: 5.462291717529297.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('problem', 'multi-outputs'),\n",
       "             ('loss',\n",
       "              {'train': 1.0389052629470825,\n",
       "               'val': 1.822463035583496,\n",
       "               'test': 5.462291717529297})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.save(con=False, dir='./models/tp_selfies.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
