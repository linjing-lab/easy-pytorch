{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-outputs Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install polars[pandas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas # or use `polars`\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_multilabel_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_multilabel_classification(n_samples=1000, \n",
    "                                      n_features=10,\n",
    "                                      n_classes=3,\n",
    "                                      n_labels=2,\n",
    "                                      random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 10), (1000, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Perming and Config Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (Linear0): Linear(in_features=10, out_features=30, bias=True)\n",
      "    (Activation0): ReLU(inplace=True)\n",
      "    (Linear1): Linear(in_features=30, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('torch -v', '1.7.1+cu101'),\n",
       "             ('criterion', MultiLabelSoftMarginLoss()),\n",
       "             ('batch_size', 8),\n",
       "             ('solver',\n",
       "              SGD (\n",
       "              Parameter Group 0\n",
       "                  dampening: 0\n",
       "                  lr: 0.01\n",
       "                  momentum: 0\n",
       "                  nesterov: False\n",
       "                  weight_decay: 0\n",
       "              )),\n",
       "             ('lr_scheduler', None),\n",
       "             ('device', device(type='cuda'))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import perming\n",
    "main = perming.Box(10, 3, (30,), batch_size=8, activation='relu', inplace_on=True, solver='sgd', criterion=\"MultiLabelSoftMarginLoss\", learning_rate_init=0.01)\n",
    "# main = perming.Ranker(10, 3, (30,), batch_size=16, activation='relu', solver='sgd', criterion=\"MultiLabelSoftMarginLoss\", learning_rate_init=0.01)\n",
    "# main = perming.COMMON_MODELS['Multi-outputs'](10, 3, (30,), batch_size=16, activation='relu', solver='sgd', criterion=\"MultiLabelSoftMarginLoss\", learning_rate_init=0.01)\n",
    "main.print_config()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader from Numpy with Multi-threaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.data_loader(X, y, random_seed=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Stage and Accelerated Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60], Step [30/100], Training Loss: 0.4972, Validation Loss: 0.0806\n",
      "Epoch [1/60], Step [60/100], Training Loss: 0.5650, Validation Loss: 0.0852\n",
      "Epoch [1/60], Step [90/100], Training Loss: 0.5776, Validation Loss: 0.0687\n",
      "Epoch [2/60], Step [30/100], Training Loss: 0.6075, Validation Loss: 0.0686\n",
      "Epoch [2/60], Step [60/100], Training Loss: 0.4606, Validation Loss: 0.0750\n",
      "Epoch [2/60], Step [90/100], Training Loss: 0.4074, Validation Loss: 0.0703\n",
      "Epoch [3/60], Step [30/100], Training Loss: 0.4135, Validation Loss: 0.0708\n",
      "Epoch [3/60], Step [60/100], Training Loss: 0.3361, Validation Loss: 0.0545\n",
      "Epoch [3/60], Step [90/100], Training Loss: 0.3046, Validation Loss: 0.0649\n",
      "Epoch [4/60], Step [30/100], Training Loss: 0.4295, Validation Loss: 0.0670\n",
      "Epoch [4/60], Step [60/100], Training Loss: 0.3505, Validation Loss: 0.0633\n",
      "Epoch [4/60], Step [90/100], Training Loss: 0.3951, Validation Loss: 0.0575\n",
      "Epoch [5/60], Step [30/100], Training Loss: 0.2866, Validation Loss: 0.0535\n",
      "Epoch [5/60], Step [60/100], Training Loss: 0.4976, Validation Loss: 0.0685\n",
      "Epoch [5/60], Step [90/100], Training Loss: 0.3728, Validation Loss: 0.0541\n",
      "Epoch [6/60], Step [30/100], Training Loss: 0.2487, Validation Loss: 0.0511\n",
      "Epoch [6/60], Step [60/100], Training Loss: 0.4090, Validation Loss: 0.0597\n",
      "Epoch [6/60], Step [90/100], Training Loss: 0.3952, Validation Loss: 0.0692\n",
      "Epoch [7/60], Step [30/100], Training Loss: 0.3935, Validation Loss: 0.0776\n",
      "Epoch [7/60], Step [60/100], Training Loss: 0.2635, Validation Loss: 0.0530\n",
      "Epoch [7/60], Step [90/100], Training Loss: 0.3450, Validation Loss: 0.0586\n",
      "Epoch [8/60], Step [30/100], Training Loss: 0.3002, Validation Loss: 0.0472\n",
      "Epoch [8/60], Step [60/100], Training Loss: 0.3290, Validation Loss: 0.0300\n",
      "Epoch [8/60], Step [90/100], Training Loss: 0.2965, Validation Loss: 0.0516\n",
      "Epoch [9/60], Step [30/100], Training Loss: 0.2828, Validation Loss: 0.0551\n",
      "Epoch [9/60], Step [60/100], Training Loss: 0.4029, Validation Loss: 0.0327\n",
      "Epoch [9/60], Step [90/100], Training Loss: 0.3393, Validation Loss: 0.0325\n",
      "Epoch [10/60], Step [30/100], Training Loss: 0.2367, Validation Loss: 0.0664\n",
      "Epoch [10/60], Step [60/100], Training Loss: 0.2399, Validation Loss: 0.0586\n",
      "Epoch [10/60], Step [90/100], Training Loss: 0.2949, Validation Loss: 0.0416\n",
      "Epoch [11/60], Step [30/100], Training Loss: 0.3079, Validation Loss: 0.0383\n",
      "Epoch [11/60], Step [60/100], Training Loss: 0.3521, Validation Loss: 0.0436\n",
      "Epoch [11/60], Step [90/100], Training Loss: 0.2018, Validation Loss: 0.0504\n",
      "Epoch [12/60], Step [30/100], Training Loss: 0.2146, Validation Loss: 0.0391\n",
      "Epoch [12/60], Step [60/100], Training Loss: 0.4735, Validation Loss: 0.0657\n",
      "Epoch [12/60], Step [90/100], Training Loss: 0.3481, Validation Loss: 0.0317\n",
      "Epoch [13/60], Step [30/100], Training Loss: 0.1200, Validation Loss: 0.0405\n",
      "Epoch [13/60], Step [60/100], Training Loss: 0.2547, Validation Loss: 0.0507\n",
      "Epoch [13/60], Step [90/100], Training Loss: 0.4334, Validation Loss: 0.0377\n",
      "Epoch [14/60], Step [30/100], Training Loss: 0.2381, Validation Loss: 0.0476\n",
      "Epoch [14/60], Step [60/100], Training Loss: 0.1866, Validation Loss: 0.0365\n",
      "Epoch [14/60], Step [90/100], Training Loss: 0.2991, Validation Loss: 0.0289\n",
      "Epoch [15/60], Step [30/100], Training Loss: 0.1794, Validation Loss: 0.0314\n",
      "Epoch [15/60], Step [60/100], Training Loss: 0.0983, Validation Loss: 0.0529\n",
      "Epoch [15/60], Step [90/100], Training Loss: 0.2119, Validation Loss: 0.0398\n",
      "Epoch [16/60], Step [30/100], Training Loss: 0.2360, Validation Loss: 0.0449\n",
      "Epoch [16/60], Step [60/100], Training Loss: 0.1424, Validation Loss: 0.0372\n",
      "Epoch [16/60], Step [90/100], Training Loss: 0.2610, Validation Loss: 0.0414\n",
      "Epoch [17/60], Step [30/100], Training Loss: 0.3082, Validation Loss: 0.0460\n",
      "Epoch [17/60], Step [60/100], Training Loss: 0.2854, Validation Loss: 0.0263\n",
      "Epoch [17/60], Step [90/100], Training Loss: 0.2065, Validation Loss: 0.0269\n",
      "Epoch [18/60], Step [30/100], Training Loss: 0.2113, Validation Loss: 0.0472\n",
      "Epoch [18/60], Step [60/100], Training Loss: 0.3028, Validation Loss: 0.0382\n",
      "Epoch [18/60], Step [90/100], Training Loss: 0.2056, Validation Loss: 0.0241\n",
      "Epoch [19/60], Step [30/100], Training Loss: 0.3086, Validation Loss: 0.0415\n",
      "Epoch [19/60], Step [60/100], Training Loss: 0.3836, Validation Loss: 0.0460\n",
      "Epoch [19/60], Step [90/100], Training Loss: 0.0884, Validation Loss: 0.0186\n",
      "Epoch [20/60], Step [30/100], Training Loss: 0.1965, Validation Loss: 0.0409\n",
      "Epoch [20/60], Step [60/100], Training Loss: 0.2342, Validation Loss: 0.0569\n",
      "Epoch [20/60], Step [90/100], Training Loss: 0.1374, Validation Loss: 0.0161\n",
      "Epoch [21/60], Step [30/100], Training Loss: 0.2448, Validation Loss: 0.0280\n",
      "Epoch [21/60], Step [60/100], Training Loss: 0.4749, Validation Loss: 0.0462\n",
      "Epoch [21/60], Step [90/100], Training Loss: 0.1975, Validation Loss: 0.0443\n",
      "Epoch [22/60], Step [30/100], Training Loss: 0.1942, Validation Loss: 0.0561\n",
      "Epoch [22/60], Step [60/100], Training Loss: 0.3399, Validation Loss: 0.0291\n",
      "Epoch [22/60], Step [90/100], Training Loss: 0.2760, Validation Loss: 0.0313\n",
      "Epoch [23/60], Step [30/100], Training Loss: 0.2111, Validation Loss: 0.0550\n",
      "Epoch [23/60], Step [60/100], Training Loss: 0.1848, Validation Loss: 0.0418\n",
      "Epoch [23/60], Step [90/100], Training Loss: 0.2714, Validation Loss: 0.0199\n",
      "Epoch [24/60], Step [30/100], Training Loss: 0.2901, Validation Loss: 0.0577\n",
      "Epoch [24/60], Step [60/100], Training Loss: 0.2910, Validation Loss: 0.0142\n",
      "Epoch [24/60], Step [90/100], Training Loss: 0.1143, Validation Loss: 0.0352\n",
      "Epoch [25/60], Step [30/100], Training Loss: 0.2540, Validation Loss: 0.0562\n",
      "Epoch [25/60], Step [60/100], Training Loss: 0.0900, Validation Loss: 0.0438\n",
      "Epoch [25/60], Step [90/100], Training Loss: 0.1216, Validation Loss: 0.0220\n",
      "Epoch [26/60], Step [30/100], Training Loss: 0.2419, Validation Loss: 0.0405\n",
      "Epoch [26/60], Step [60/100], Training Loss: 0.2274, Validation Loss: 0.0331\n",
      "Epoch [26/60], Step [90/100], Training Loss: 0.0664, Validation Loss: 0.0293\n",
      "Epoch [27/60], Step [30/100], Training Loss: 0.3055, Validation Loss: 0.0138\n",
      "Epoch [27/60], Step [60/100], Training Loss: 0.1122, Validation Loss: 0.0613\n",
      "Epoch [27/60], Step [90/100], Training Loss: 0.1017, Validation Loss: 0.0569\n",
      "Epoch [28/60], Step [30/100], Training Loss: 0.4029, Validation Loss: 0.0400\n",
      "Epoch [28/60], Step [60/100], Training Loss: 0.1683, Validation Loss: 0.0289\n",
      "Epoch [28/60], Step [90/100], Training Loss: 0.2200, Validation Loss: 0.0468\n",
      "Epoch [29/60], Step [30/100], Training Loss: 0.2781, Validation Loss: 0.0154\n",
      "Epoch [29/60], Step [60/100], Training Loss: 0.1893, Validation Loss: 0.0471\n",
      "Epoch [29/60], Step [90/100], Training Loss: 0.2179, Validation Loss: 0.0516\n",
      "Epoch [30/60], Step [30/100], Training Loss: 0.2297, Validation Loss: 0.0602\n",
      "Epoch [30/60], Step [60/100], Training Loss: 0.1557, Validation Loss: 0.0186\n",
      "Epoch [30/60], Step [90/100], Training Loss: 0.2419, Validation Loss: 0.0434\n",
      "Epoch [31/60], Step [30/100], Training Loss: 0.2316, Validation Loss: 0.0406\n",
      "Epoch [31/60], Step [60/100], Training Loss: 0.1091, Validation Loss: 0.0542\n",
      "Epoch [31/60], Step [90/100], Training Loss: 0.0817, Validation Loss: 0.0264\n",
      "Epoch [32/60], Step [30/100], Training Loss: 0.4144, Validation Loss: 0.0204\n",
      "Epoch [32/60], Step [60/100], Training Loss: 0.0616, Validation Loss: 0.0333\n",
      "Epoch [32/60], Step [90/100], Training Loss: 0.6966, Validation Loss: 0.0392\n",
      "Epoch [33/60], Step [30/100], Training Loss: 0.1954, Validation Loss: 0.0151\n",
      "Epoch [33/60], Step [60/100], Training Loss: 0.1475, Validation Loss: 0.0163\n",
      "Epoch [33/60], Step [90/100], Training Loss: 0.2324, Validation Loss: 0.0438\n",
      "Epoch [34/60], Step [30/100], Training Loss: 0.3183, Validation Loss: 0.0626\n",
      "Epoch [34/60], Step [60/100], Training Loss: 0.3219, Validation Loss: 0.0351\n",
      "Epoch [34/60], Step [90/100], Training Loss: 0.2377, Validation Loss: 0.0470\n",
      "Epoch [35/60], Step [30/100], Training Loss: 0.2225, Validation Loss: 0.0359\n",
      "Epoch [35/60], Step [60/100], Training Loss: 0.2362, Validation Loss: 0.0585\n",
      "Epoch [35/60], Step [90/100], Training Loss: 0.1547, Validation Loss: 0.0185\n",
      "Epoch [36/60], Step [30/100], Training Loss: 0.1960, Validation Loss: 0.0215\n",
      "Epoch [36/60], Step [60/100], Training Loss: 0.1979, Validation Loss: 0.0485\n",
      "Epoch [36/60], Step [90/100], Training Loss: 0.1090, Validation Loss: 0.0276\n",
      "Epoch [37/60], Step [30/100], Training Loss: 0.1049, Validation Loss: 0.0385\n",
      "Epoch [37/60], Step [60/100], Training Loss: 0.2301, Validation Loss: 0.0624\n",
      "Epoch [37/60], Step [90/100], Training Loss: 0.0848, Validation Loss: 0.0412\n",
      "Epoch [38/60], Step [30/100], Training Loss: 0.1059, Validation Loss: 0.0400\n",
      "Epoch [38/60], Step [60/100], Training Loss: 0.5230, Validation Loss: 0.0157\n",
      "Epoch [38/60], Step [90/100], Training Loss: 0.3256, Validation Loss: 0.0141\n",
      "Epoch [39/60], Step [30/100], Training Loss: 0.1666, Validation Loss: 0.0659\n",
      "Epoch [39/60], Step [60/100], Training Loss: 0.1619, Validation Loss: 0.0207\n",
      "Epoch [39/60], Step [90/100], Training Loss: 0.2664, Validation Loss: 0.0567\n",
      "Epoch [40/60], Step [30/100], Training Loss: 0.1574, Validation Loss: 0.0395\n",
      "Epoch [40/60], Step [60/100], Training Loss: 0.1833, Validation Loss: 0.0113\n",
      "Epoch [40/60], Step [90/100], Training Loss: 0.1610, Validation Loss: 0.0208\n",
      "Epoch [41/60], Step [30/100], Training Loss: 0.1414, Validation Loss: 0.0390\n",
      "Epoch [41/60], Step [60/100], Training Loss: 0.1421, Validation Loss: 0.0270\n",
      "Epoch [41/60], Step [90/100], Training Loss: 0.1884, Validation Loss: 0.0409\n",
      "Epoch [42/60], Step [30/100], Training Loss: 0.6698, Validation Loss: 0.0319\n",
      "Epoch [42/60], Step [60/100], Training Loss: 0.2011, Validation Loss: 0.0474\n",
      "Epoch [42/60], Step [90/100], Training Loss: 0.2132, Validation Loss: 0.0490\n",
      "Epoch [43/60], Step [30/100], Training Loss: 0.4074, Validation Loss: 0.0245\n",
      "Epoch [43/60], Step [60/100], Training Loss: 0.1428, Validation Loss: 0.0409\n",
      "Epoch [43/60], Step [90/100], Training Loss: 0.1920, Validation Loss: 0.0190\n",
      "Epoch [44/60], Step [30/100], Training Loss: 0.1831, Validation Loss: 0.0409\n",
      "Epoch [44/60], Step [60/100], Training Loss: 0.1155, Validation Loss: 0.0614\n",
      "Epoch [44/60], Step [90/100], Training Loss: 0.2148, Validation Loss: 0.0117\n",
      "Epoch [45/60], Step [30/100], Training Loss: 0.1979, Validation Loss: 0.0211\n",
      "Epoch [45/60], Step [60/100], Training Loss: 0.0873, Validation Loss: 0.0391\n",
      "Epoch [45/60], Step [90/100], Training Loss: 0.0893, Validation Loss: 0.0401\n",
      "Epoch [46/60], Step [30/100], Training Loss: 0.1199, Validation Loss: 0.0210\n",
      "Epoch [46/60], Step [60/100], Training Loss: 0.0604, Validation Loss: 0.0241\n",
      "Epoch [46/60], Step [90/100], Training Loss: 0.3094, Validation Loss: 0.0288\n",
      "Epoch [47/60], Step [30/100], Training Loss: 0.1083, Validation Loss: 0.0394\n",
      "Epoch [47/60], Step [60/100], Training Loss: 0.1128, Validation Loss: 0.0505\n",
      "Epoch [47/60], Step [90/100], Training Loss: 0.1646, Validation Loss: 0.0276\n",
      "Epoch [48/60], Step [30/100], Training Loss: 0.1184, Validation Loss: 0.0460\n",
      "Epoch [48/60], Step [60/100], Training Loss: 0.1902, Validation Loss: 0.0114\n",
      "Epoch [48/60], Step [90/100], Training Loss: 0.2216, Validation Loss: 0.0234\n",
      "Epoch [49/60], Step [30/100], Training Loss: 0.1518, Validation Loss: 0.0387\n",
      "Epoch [49/60], Step [60/100], Training Loss: 0.2320, Validation Loss: 0.0209\n",
      "Epoch [49/60], Step [90/100], Training Loss: 0.1432, Validation Loss: 0.0137\n",
      "Epoch [50/60], Step [30/100], Training Loss: 0.0964, Validation Loss: 0.0478\n",
      "Epoch [50/60], Step [60/100], Training Loss: 0.1055, Validation Loss: 0.0261\n",
      "Epoch [50/60], Step [90/100], Training Loss: 0.1544, Validation Loss: 0.0417\n",
      "Epoch [51/60], Step [30/100], Training Loss: 0.0476, Validation Loss: 0.0143\n",
      "Epoch [51/60], Step [60/100], Training Loss: 0.3036, Validation Loss: 0.0460\n",
      "Epoch [51/60], Step [90/100], Training Loss: 0.1385, Validation Loss: 0.0550\n",
      "Epoch [52/60], Step [30/100], Training Loss: 0.0319, Validation Loss: 0.0401\n",
      "Epoch [52/60], Step [60/100], Training Loss: 0.1742, Validation Loss: 0.0288\n",
      "Epoch [52/60], Step [90/100], Training Loss: 0.2432, Validation Loss: 0.0258\n",
      "Epoch [53/60], Step [30/100], Training Loss: 0.1270, Validation Loss: 0.0493\n",
      "Epoch [53/60], Step [60/100], Training Loss: 0.1183, Validation Loss: 0.0127\n",
      "Epoch [53/60], Step [90/100], Training Loss: 0.0340, Validation Loss: 0.0264\n",
      "Epoch [54/60], Step [30/100], Training Loss: 0.3926, Validation Loss: 0.0194\n",
      "Epoch [54/60], Step [60/100], Training Loss: 0.2363, Validation Loss: 0.0378\n",
      "Epoch [54/60], Step [90/100], Training Loss: 0.1296, Validation Loss: 0.0160\n",
      "Epoch [55/60], Step [30/100], Training Loss: 0.2363, Validation Loss: 0.0200\n",
      "Epoch [55/60], Step [60/100], Training Loss: 0.1006, Validation Loss: 0.0469\n",
      "Epoch [55/60], Step [90/100], Training Loss: 0.3356, Validation Loss: 0.0387\n",
      "Epoch [56/60], Step [30/100], Training Loss: 0.0713, Validation Loss: 0.0478\n",
      "Epoch [56/60], Step [60/100], Training Loss: 0.0812, Validation Loss: 0.0585\n",
      "Epoch [56/60], Step [90/100], Training Loss: 0.1775, Validation Loss: 0.0192\n",
      "Epoch [57/60], Step [30/100], Training Loss: 0.1338, Validation Loss: 0.0144\n",
      "Epoch [57/60], Step [60/100], Training Loss: 0.2726, Validation Loss: 0.0236\n",
      "Epoch [57/60], Step [90/100], Training Loss: 0.1773, Validation Loss: 0.0201\n",
      "Epoch [58/60], Step [30/100], Training Loss: 0.0757, Validation Loss: 0.0277\n",
      "Epoch [58/60], Step [60/100], Training Loss: 0.2152, Validation Loss: 0.0221\n",
      "Epoch [58/60], Step [90/100], Training Loss: 0.0482, Validation Loss: 0.0195\n",
      "Epoch [59/60], Step [30/100], Training Loss: 0.4359, Validation Loss: 0.0360\n",
      "Epoch [59/60], Step [60/100], Training Loss: 0.1479, Validation Loss: 0.0323\n",
      "Epoch [59/60], Step [90/100], Training Loss: 0.1874, Validation Loss: 0.0441\n",
      "Epoch [60/60], Step [30/100], Training Loss: 0.2968, Validation Loss: 0.0498\n",
      "Epoch [60/60], Step [60/100], Training Loss: 0.1198, Validation Loss: 0.0398\n",
      "Epoch [60/60], Step [90/100], Training Loss: 0.3162, Validation Loss: 0.0256\n"
     ]
    }
   ],
   "source": [
    "main.train_val(num_epochs=60, interval=30, tolerance=1e-4, patience=10, early_stop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model with Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of Box on the 104 test dataset: 0.12606360018253326.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('problem', 'multi-outputs'),\n",
       "             ('loss',\n",
       "              {'train': 0.17552965879440308,\n",
       "               'val': 0.010736284777522087,\n",
       "               'test': 0.12606360018253326})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = torch.as_tensor(X, dtype=torch.float).to(torch.device(\"cuda\")), torch.as_tensor(y, dtype=torch.float).to(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = main.model(X) # predicted\n",
    "# refer to https://pytorch.org/torcheval/main/ for metrics functional tools, like classification\n",
    "# take input as pred, target as y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'82.8%'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{}%'.format(100 * sum(row.all().int().item() for row in (pred.ge(0.5) == y)) / X.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model Parameters to Models Folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.save(con=False, dir='../models/outputs.ckpt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model Parameters from Models Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.load(con=False, dir='../models/outputs.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
