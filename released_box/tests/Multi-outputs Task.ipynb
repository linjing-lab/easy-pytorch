{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-outputs Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install polars[pandas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas # or use `polars`\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_multilabel_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_multilabel_classification(n_samples=1000, \n",
    "                                      n_features=10,\n",
    "                                      n_classes=3,\n",
    "                                      n_labels=2,\n",
    "                                      random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 10), (1000, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Perming and Config Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (Linear0): Linear(in_features=10, out_features=30, bias=True)\n",
      "    (Activation0): ReLU(inplace=True)\n",
      "    (Linear1): Linear(in_features=30, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('torch -v', '1.7.1+cu101'),\n",
       "             ('criterion', MultiLabelSoftMarginLoss()),\n",
       "             ('batch_size', 8),\n",
       "             ('solver',\n",
       "              SGD (\n",
       "              Parameter Group 0\n",
       "                  dampening: 0\n",
       "                  lr: 0.01\n",
       "                  momentum: 0\n",
       "                  nesterov: False\n",
       "                  weight_decay: 0\n",
       "              )),\n",
       "             ('lr_scheduler', None),\n",
       "             ('device', device(type='cuda'))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import perming\n",
    "main = perming.Box(10, 3, (30,), batch_size=8, activation='relu', inplace_on=True, solver='sgd', criterion=\"MultiLabelSoftMarginLoss\", learning_rate_init=0.01)\n",
    "# main = perming.Ranker(10, 3, (30,), batch_size=16, activation='relu', solver='sgd', criterion=\"MultiLabelSoftMarginLoss\", learning_rate_init=0.01)\n",
    "# main = perming.COMMON_MODELS['Multi-outputs'](10, 3, (30,), batch_size=16, activation='relu', solver='sgd', criterion=\"MultiLabelSoftMarginLoss\", learning_rate_init=0.01)\n",
    "main.print_config()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader from Numpy with Multi-threaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.data_loader(X, y, random_seed=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Stage and Accelerated Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40], Step [10/100], Training Loss: 0.8111, Validation Loss: 0.6473\n",
      "Epoch [1/40], Step [20/100], Training Loss: 0.6409, Validation Loss: 0.6319\n",
      "Epoch [1/40], Step [30/100], Training Loss: 0.5722, Validation Loss: 0.6216\n",
      "Epoch [1/40], Step [40/100], Training Loss: 0.5732, Validation Loss: 0.6015\n",
      "Epoch [1/40], Step [50/100], Training Loss: 0.7571, Validation Loss: 0.5837\n",
      "Epoch [1/40], Step [60/100], Training Loss: 0.5953, Validation Loss: 0.5720\n",
      "Epoch [1/40], Step [70/100], Training Loss: 0.4726, Validation Loss: 0.5622\n",
      "Epoch [1/40], Step [80/100], Training Loss: 0.5246, Validation Loss: 0.5515\n",
      "Epoch [1/40], Step [90/100], Training Loss: 0.6551, Validation Loss: 0.5410\n",
      "Epoch [1/40], Step [100/100], Training Loss: 0.4357, Validation Loss: 0.5401\n",
      "Epoch [2/40], Step [10/100], Training Loss: 0.6371, Validation Loss: 0.5278\n",
      "Epoch [2/40], Step [20/100], Training Loss: 0.4437, Validation Loss: 0.5240\n",
      "Epoch [2/40], Step [30/100], Training Loss: 0.5097, Validation Loss: 0.5322\n",
      "Epoch [2/40], Step [40/100], Training Loss: 0.3537, Validation Loss: 0.5104\n",
      "Epoch [2/40], Step [50/100], Training Loss: 0.5897, Validation Loss: 0.5102\n",
      "Epoch [2/40], Step [60/100], Training Loss: 0.4253, Validation Loss: 0.4986\n",
      "Epoch [2/40], Step [70/100], Training Loss: 0.4365, Validation Loss: 0.4906\n",
      "Epoch [2/40], Step [80/100], Training Loss: 0.5527, Validation Loss: 0.4834\n",
      "Epoch [2/40], Step [90/100], Training Loss: 0.3954, Validation Loss: 0.4777\n",
      "Epoch [2/40], Step [100/100], Training Loss: 0.3482, Validation Loss: 0.4716\n",
      "Epoch [3/40], Step [10/100], Training Loss: 0.4525, Validation Loss: 0.4635\n",
      "Epoch [3/40], Step [20/100], Training Loss: 0.4815, Validation Loss: 0.4672\n",
      "Epoch [3/40], Step [30/100], Training Loss: 0.3279, Validation Loss: 0.4593\n",
      "Epoch [3/40], Step [40/100], Training Loss: 0.5291, Validation Loss: 0.4526\n",
      "Epoch [3/40], Step [50/100], Training Loss: 0.3865, Validation Loss: 0.4480\n",
      "Epoch [3/40], Step [60/100], Training Loss: 0.3348, Validation Loss: 0.4427\n",
      "Epoch [3/40], Step [70/100], Training Loss: 0.3124, Validation Loss: 0.4472\n",
      "Epoch [3/40], Step [80/100], Training Loss: 0.4072, Validation Loss: 0.4407\n",
      "Epoch [3/40], Step [90/100], Training Loss: 0.3876, Validation Loss: 0.4416\n",
      "Epoch [3/40], Step [100/100], Training Loss: 0.3662, Validation Loss: 0.4337\n",
      "Epoch [4/40], Step [10/100], Training Loss: 0.4150, Validation Loss: 0.4281\n",
      "Epoch [4/40], Step [20/100], Training Loss: 0.4558, Validation Loss: 0.4221\n",
      "Epoch [4/40], Step [30/100], Training Loss: 0.3299, Validation Loss: 0.4287\n",
      "Epoch [4/40], Step [40/100], Training Loss: 0.4462, Validation Loss: 0.4294\n",
      "Epoch [4/40], Step [50/100], Training Loss: 0.2534, Validation Loss: 0.4266\n",
      "Epoch [4/40], Step [60/100], Training Loss: 0.3111, Validation Loss: 0.4154\n",
      "Epoch [4/40], Step [70/100], Training Loss: 0.4327, Validation Loss: 0.4139\n",
      "Epoch [4/40], Step [80/100], Training Loss: 0.4802, Validation Loss: 0.4132\n",
      "Epoch [4/40], Step [90/100], Training Loss: 0.4956, Validation Loss: 0.4023\n",
      "Epoch [4/40], Step [100/100], Training Loss: 0.3576, Validation Loss: 0.4051\n",
      "Epoch [5/40], Step [10/100], Training Loss: 0.3436, Validation Loss: 0.4078\n",
      "Epoch [5/40], Step [20/100], Training Loss: 0.4039, Validation Loss: 0.4044\n",
      "Epoch [5/40], Step [30/100], Training Loss: 0.5586, Validation Loss: 0.3991\n",
      "Epoch [5/40], Step [40/100], Training Loss: 0.4244, Validation Loss: 0.3965\n",
      "Epoch [5/40], Step [50/100], Training Loss: 0.3708, Validation Loss: 0.3939\n",
      "Epoch [5/40], Step [60/100], Training Loss: 0.4254, Validation Loss: 0.3903\n",
      "Epoch [5/40], Step [70/100], Training Loss: 0.2471, Validation Loss: 0.3906\n",
      "Epoch [5/40], Step [80/100], Training Loss: 0.3390, Validation Loss: 0.3879\n",
      "Epoch [5/40], Step [90/100], Training Loss: 0.3699, Validation Loss: 0.3893\n",
      "Epoch [5/40], Step [100/100], Training Loss: 0.4111, Validation Loss: 0.3833\n",
      "Epoch [6/40], Step [10/100], Training Loss: 0.3870, Validation Loss: 0.3831\n",
      "Epoch [6/40], Step [20/100], Training Loss: 0.3957, Validation Loss: 0.3790\n",
      "Epoch [6/40], Step [30/100], Training Loss: 0.3183, Validation Loss: 0.3789\n",
      "Epoch [6/40], Step [40/100], Training Loss: 0.3030, Validation Loss: 0.3764\n",
      "Epoch [6/40], Step [50/100], Training Loss: 0.3327, Validation Loss: 0.3752\n",
      "Epoch [6/40], Step [60/100], Training Loss: 0.3702, Validation Loss: 0.3730\n",
      "Epoch [6/40], Step [70/100], Training Loss: 0.2255, Validation Loss: 0.3722\n",
      "Epoch [6/40], Step [80/100], Training Loss: 0.3572, Validation Loss: 0.3739\n",
      "Epoch [6/40], Step [90/100], Training Loss: 0.3819, Validation Loss: 0.3704\n",
      "Epoch [6/40], Step [100/100], Training Loss: 0.1674, Validation Loss: 0.3636\n",
      "Epoch [7/40], Step [10/100], Training Loss: 0.3450, Validation Loss: 0.3689\n",
      "Epoch [7/40], Step [20/100], Training Loss: 0.6311, Validation Loss: 0.3619\n",
      "Epoch [7/40], Step [30/100], Training Loss: 0.3974, Validation Loss: 0.3641\n",
      "Epoch [7/40], Step [40/100], Training Loss: 0.2833, Validation Loss: 0.3555\n",
      "Epoch [7/40], Step [50/100], Training Loss: 0.3843, Validation Loss: 0.3578\n",
      "Epoch [7/40], Step [60/100], Training Loss: 0.2745, Validation Loss: 0.3555\n",
      "Epoch [7/40], Step [70/100], Training Loss: 0.2445, Validation Loss: 0.3565\n",
      "Epoch [7/40], Step [80/100], Training Loss: 0.2608, Validation Loss: 0.3549\n",
      "Epoch [7/40], Step [90/100], Training Loss: 0.2673, Validation Loss: 0.3624\n",
      "Epoch [7/40], Step [100/100], Training Loss: 0.5033, Validation Loss: 0.3593\n",
      "Epoch [8/40], Step [10/100], Training Loss: 0.4149, Validation Loss: 0.3570\n",
      "Epoch [8/40], Step [20/100], Training Loss: 0.3428, Validation Loss: 0.3565\n",
      "Epoch [8/40], Step [30/100], Training Loss: 0.2113, Validation Loss: 0.3464\n",
      "Epoch [8/40], Step [40/100], Training Loss: 0.2315, Validation Loss: 0.3456\n",
      "Epoch [8/40], Step [50/100], Training Loss: 0.4349, Validation Loss: 0.3420\n",
      "Epoch [8/40], Step [60/100], Training Loss: 0.1508, Validation Loss: 0.3431\n",
      "Epoch [8/40], Step [70/100], Training Loss: 0.3207, Validation Loss: 0.3441\n",
      "Epoch [8/40], Step [80/100], Training Loss: 0.3945, Validation Loss: 0.3433\n",
      "Epoch [8/40], Step [90/100], Training Loss: 0.2364, Validation Loss: 0.3482\n",
      "Epoch [8/40], Step [100/100], Training Loss: 0.2772, Validation Loss: 0.3494\n",
      "Epoch [9/40], Step [10/100], Training Loss: 0.2810, Validation Loss: 0.3401\n",
      "Epoch [9/40], Step [20/100], Training Loss: 0.2683, Validation Loss: 0.3380\n",
      "Epoch [9/40], Step [30/100], Training Loss: 0.2768, Validation Loss: 0.3374\n",
      "Epoch [9/40], Step [40/100], Training Loss: 0.4514, Validation Loss: 0.3429\n",
      "Epoch [9/40], Step [50/100], Training Loss: 0.1290, Validation Loss: 0.3335\n",
      "Epoch [9/40], Step [60/100], Training Loss: 0.1324, Validation Loss: 0.3327\n",
      "Epoch [9/40], Step [70/100], Training Loss: 0.3693, Validation Loss: 0.3313\n",
      "Epoch [9/40], Step [80/100], Training Loss: 0.3439, Validation Loss: 0.3305\n",
      "Epoch [9/40], Step [90/100], Training Loss: 0.4747, Validation Loss: 0.3425\n",
      "Epoch [9/40], Step [100/100], Training Loss: 0.1910, Validation Loss: 0.3275\n",
      "Epoch [10/40], Step [10/100], Training Loss: 0.2786, Validation Loss: 0.3289\n",
      "Epoch [10/40], Step [20/100], Training Loss: 0.5020, Validation Loss: 0.3279\n",
      "Epoch [10/40], Step [30/100], Training Loss: 0.3423, Validation Loss: 0.3269\n",
      "Epoch [10/40], Step [40/100], Training Loss: 0.3530, Validation Loss: 0.3264\n",
      "Epoch [10/40], Step [50/100], Training Loss: 0.3029, Validation Loss: 0.3270\n",
      "Epoch [10/40], Step [60/100], Training Loss: 0.2573, Validation Loss: 0.3263\n",
      "Epoch [10/40], Step [70/100], Training Loss: 0.3440, Validation Loss: 0.3241\n",
      "Epoch [10/40], Step [80/100], Training Loss: 0.2654, Validation Loss: 0.3245\n",
      "Epoch [10/40], Step [90/100], Training Loss: 0.2710, Validation Loss: 0.3321\n",
      "Epoch [10/40], Step [100/100], Training Loss: 0.0935, Validation Loss: 0.3236\n",
      "Epoch [11/40], Step [10/100], Training Loss: 0.2682, Validation Loss: 0.3259\n",
      "Epoch [11/40], Step [20/100], Training Loss: 0.3353, Validation Loss: 0.3274\n",
      "Epoch [11/40], Step [30/100], Training Loss: 0.1926, Validation Loss: 0.3243\n",
      "Epoch [11/40], Step [40/100], Training Loss: 0.2779, Validation Loss: 0.3238\n",
      "Epoch [11/40], Step [50/100], Training Loss: 0.1346, Validation Loss: 0.3206\n",
      "Epoch [11/40], Step [60/100], Training Loss: 0.3106, Validation Loss: 0.3285\n",
      "Epoch [11/40], Step [70/100], Training Loss: 0.2791, Validation Loss: 0.3237\n",
      "Epoch [11/40], Step [80/100], Training Loss: 0.2588, Validation Loss: 0.3135\n",
      "Epoch [11/40], Step [90/100], Training Loss: 0.3174, Validation Loss: 0.3158\n",
      "Epoch [11/40], Step [100/100], Training Loss: 0.2465, Validation Loss: 0.3142\n",
      "Epoch [12/40], Step [10/100], Training Loss: 0.2924, Validation Loss: 0.3170\n",
      "Epoch [12/40], Step [20/100], Training Loss: 0.2115, Validation Loss: 0.3150\n",
      "Epoch [12/40], Step [30/100], Training Loss: 0.3137, Validation Loss: 0.3191\n",
      "Epoch [12/40], Step [40/100], Training Loss: 0.2442, Validation Loss: 0.3134\n",
      "Epoch [12/40], Step [50/100], Training Loss: 0.1994, Validation Loss: 0.3141\n",
      "Epoch [12/40], Step [60/100], Training Loss: 0.3227, Validation Loss: 0.3152\n",
      "Epoch [12/40], Step [70/100], Training Loss: 0.1995, Validation Loss: 0.3102\n",
      "Epoch [12/40], Step [80/100], Training Loss: 0.4512, Validation Loss: 0.3081\n",
      "Epoch [12/40], Step [90/100], Training Loss: 0.1962, Validation Loss: 0.3102\n",
      "Epoch [12/40], Step [100/100], Training Loss: 0.3424, Validation Loss: 0.3067\n",
      "Epoch [13/40], Step [10/100], Training Loss: 0.2376, Validation Loss: 0.3079\n",
      "Epoch [13/40], Step [20/100], Training Loss: 0.4355, Validation Loss: 0.3134\n",
      "Epoch [13/40], Step [30/100], Training Loss: 0.3978, Validation Loss: 0.3069\n",
      "Epoch [13/40], Step [40/100], Training Loss: 0.2687, Validation Loss: 0.3087\n",
      "Epoch [13/40], Step [50/100], Training Loss: 0.3075, Validation Loss: 0.3192\n",
      "Epoch [13/40], Step [60/100], Training Loss: 0.3746, Validation Loss: 0.3057\n",
      "Epoch [13/40], Step [70/100], Training Loss: 0.3373, Validation Loss: 0.3037\n",
      "Epoch [13/40], Step [80/100], Training Loss: 0.2947, Validation Loss: 0.3062\n",
      "Epoch [13/40], Step [90/100], Training Loss: 0.1979, Validation Loss: 0.3154\n",
      "Epoch [13/40], Step [100/100], Training Loss: 0.3020, Validation Loss: 0.3050\n",
      "Epoch [14/40], Step [10/100], Training Loss: 0.2444, Validation Loss: 0.3015\n",
      "Epoch [14/40], Step [20/100], Training Loss: 0.2228, Validation Loss: 0.3080\n",
      "Epoch [14/40], Step [30/100], Training Loss: 0.3547, Validation Loss: 0.2995\n",
      "Epoch [14/40], Step [40/100], Training Loss: 0.3064, Validation Loss: 0.3008\n",
      "Epoch [14/40], Step [50/100], Training Loss: 0.3366, Validation Loss: 0.3112\n",
      "Epoch [14/40], Step [60/100], Training Loss: 0.2858, Validation Loss: 0.3030\n",
      "Epoch [14/40], Step [70/100], Training Loss: 0.1970, Validation Loss: 0.3001\n",
      "Epoch [14/40], Step [80/100], Training Loss: 0.2464, Validation Loss: 0.3010\n",
      "Epoch [14/40], Step [90/100], Training Loss: 0.3523, Validation Loss: 0.2989\n",
      "Epoch [14/40], Step [100/100], Training Loss: 0.1668, Validation Loss: 0.3161\n",
      "Epoch [15/40], Step [10/100], Training Loss: 0.4937, Validation Loss: 0.3001\n",
      "Epoch [15/40], Step [20/100], Training Loss: 0.3389, Validation Loss: 0.3048\n",
      "Epoch [15/40], Step [30/100], Training Loss: 0.2476, Validation Loss: 0.3004\n",
      "Epoch [15/40], Step [40/100], Training Loss: 0.2426, Validation Loss: 0.3015\n",
      "Epoch [15/40], Step [50/100], Training Loss: 0.1900, Validation Loss: 0.3052\n",
      "Epoch [15/40], Step [60/100], Training Loss: 0.2918, Validation Loss: 0.3014\n",
      "Epoch [15/40], Step [70/100], Training Loss: 0.1703, Validation Loss: 0.2980\n",
      "Epoch [15/40], Step [80/100], Training Loss: 0.3757, Validation Loss: 0.3064\n",
      "Epoch [15/40], Step [90/100], Training Loss: 0.3761, Validation Loss: 0.3046\n",
      "Epoch [15/40], Step [100/100], Training Loss: 0.2024, Validation Loss: 0.2958\n",
      "Epoch [16/40], Step [10/100], Training Loss: 0.1943, Validation Loss: 0.2923\n",
      "Epoch [16/40], Step [20/100], Training Loss: 0.2773, Validation Loss: 0.3049\n",
      "Epoch [16/40], Step [30/100], Training Loss: 0.2837, Validation Loss: 0.2990\n",
      "Epoch [16/40], Step [40/100], Training Loss: 0.5279, Validation Loss: 0.2947\n",
      "Epoch [16/40], Step [50/100], Training Loss: 0.3288, Validation Loss: 0.2946\n",
      "Epoch [16/40], Step [60/100], Training Loss: 0.3673, Validation Loss: 0.2894\n",
      "Epoch [16/40], Step [70/100], Training Loss: 0.2560, Validation Loss: 0.2994\n",
      "Epoch [16/40], Step [80/100], Training Loss: 0.2797, Validation Loss: 0.2940\n",
      "Epoch [16/40], Step [90/100], Training Loss: 0.3080, Validation Loss: 0.2925\n",
      "Epoch [16/40], Step [100/100], Training Loss: 0.2769, Validation Loss: 0.2949\n",
      "Epoch [17/40], Step [10/100], Training Loss: 0.0754, Validation Loss: 0.2943\n",
      "Epoch [17/40], Step [20/100], Training Loss: 0.2652, Validation Loss: 0.2876\n",
      "Epoch [17/40], Step [30/100], Training Loss: 0.2431, Validation Loss: 0.2907\n",
      "Epoch [17/40], Step [40/100], Training Loss: 0.2486, Validation Loss: 0.2892\n",
      "Epoch [17/40], Step [50/100], Training Loss: 0.1412, Validation Loss: 0.2919\n",
      "Epoch [17/40], Step [60/100], Training Loss: 0.2518, Validation Loss: 0.2904\n",
      "Epoch [17/40], Step [70/100], Training Loss: 0.3082, Validation Loss: 0.2934\n",
      "Epoch [17/40], Step [80/100], Training Loss: 0.3361, Validation Loss: 0.2874\n",
      "Epoch [17/40], Step [90/100], Training Loss: 0.2832, Validation Loss: 0.2982\n",
      "Epoch [17/40], Step [100/100], Training Loss: 0.1927, Validation Loss: 0.2922\n",
      "Epoch [18/40], Step [10/100], Training Loss: 0.2918, Validation Loss: 0.2887\n",
      "Epoch [18/40], Step [20/100], Training Loss: 0.1369, Validation Loss: 0.2864\n",
      "Epoch [18/40], Step [30/100], Training Loss: 0.0814, Validation Loss: 0.2856\n",
      "Epoch [18/40], Step [40/100], Training Loss: 0.0914, Validation Loss: 0.2869\n",
      "Epoch [18/40], Step [50/100], Training Loss: 0.3965, Validation Loss: 0.2884\n",
      "Epoch [18/40], Step [60/100], Training Loss: 0.1743, Validation Loss: 0.2877\n",
      "Epoch [18/40], Step [70/100], Training Loss: 0.3602, Validation Loss: 0.2984\n",
      "Epoch [18/40], Step [80/100], Training Loss: 0.2116, Validation Loss: 0.2968\n",
      "Epoch [18/40], Step [90/100], Training Loss: 0.2790, Validation Loss: 0.2924\n",
      "Epoch [18/40], Step [100/100], Training Loss: 0.3472, Validation Loss: 0.2851\n",
      "Epoch [19/40], Step [10/100], Training Loss: 0.1876, Validation Loss: 0.2844\n",
      "Epoch [19/40], Step [20/100], Training Loss: 0.2239, Validation Loss: 0.2958\n",
      "Epoch [19/40], Step [30/100], Training Loss: 0.2695, Validation Loss: 0.2910\n",
      "Epoch [19/40], Step [40/100], Training Loss: 0.1219, Validation Loss: 0.2844\n",
      "Epoch [19/40], Step [50/100], Training Loss: 0.3117, Validation Loss: 0.2880\n",
      "Epoch [19/40], Step [60/100], Training Loss: 0.2071, Validation Loss: 0.2859\n",
      "Epoch [19/40], Step [70/100], Training Loss: 0.3050, Validation Loss: 0.2842\n",
      "Epoch [19/40], Step [80/100], Training Loss: 0.2306, Validation Loss: 0.2825\n",
      "Epoch [19/40], Step [90/100], Training Loss: 0.1287, Validation Loss: 0.2803\n",
      "Epoch [19/40], Step [100/100], Training Loss: 0.2898, Validation Loss: 0.2801\n",
      "Epoch [20/40], Step [10/100], Training Loss: 0.2383, Validation Loss: 0.2813\n",
      "Epoch [20/40], Step [20/100], Training Loss: 0.2052, Validation Loss: 0.2780\n",
      "Epoch [20/40], Step [30/100], Training Loss: 0.1169, Validation Loss: 0.2803\n",
      "Epoch [20/40], Step [40/100], Training Loss: 0.0847, Validation Loss: 0.2812\n",
      "Epoch [20/40], Step [50/100], Training Loss: 0.2081, Validation Loss: 0.2818\n",
      "Epoch [20/40], Step [60/100], Training Loss: 0.0979, Validation Loss: 0.2821\n",
      "Epoch [20/40], Step [70/100], Training Loss: 0.1810, Validation Loss: 0.2851\n",
      "Epoch [20/40], Step [80/100], Training Loss: 0.1160, Validation Loss: 0.2795\n",
      "Epoch [20/40], Step [90/100], Training Loss: 0.4532, Validation Loss: 0.3113\n",
      "Epoch [20/40], Step [100/100], Training Loss: 0.3030, Validation Loss: 0.2807\n",
      "Epoch [21/40], Step [10/100], Training Loss: 0.2674, Validation Loss: 0.2825\n",
      "Epoch [21/40], Step [20/100], Training Loss: 0.4575, Validation Loss: 0.2838\n",
      "Epoch [21/40], Step [30/100], Training Loss: 0.0952, Validation Loss: 0.2894\n",
      "Epoch [21/40], Step [40/100], Training Loss: 0.2462, Validation Loss: 0.2755\n",
      "Epoch [21/40], Step [50/100], Training Loss: 0.2984, Validation Loss: 0.2771\n",
      "Epoch [21/40], Step [60/100], Training Loss: 0.1999, Validation Loss: 0.2784\n",
      "Epoch [21/40], Step [70/100], Training Loss: 0.1063, Validation Loss: 0.2865\n",
      "Epoch [21/40], Step [80/100], Training Loss: 0.2900, Validation Loss: 0.2897\n",
      "Epoch [21/40], Step [90/100], Training Loss: 0.2548, Validation Loss: 0.3013\n",
      "Epoch [21/40], Step [100/100], Training Loss: 0.2730, Validation Loss: 0.2745\n",
      "Epoch [22/40], Step [10/100], Training Loss: 0.2826, Validation Loss: 0.2923\n",
      "Epoch [22/40], Step [20/100], Training Loss: 0.2581, Validation Loss: 0.2845\n",
      "Epoch [22/40], Step [30/100], Training Loss: 0.4604, Validation Loss: 0.2841\n",
      "Epoch [22/40], Step [40/100], Training Loss: 0.2801, Validation Loss: 0.2820\n",
      "Epoch [22/40], Step [50/100], Training Loss: 0.3653, Validation Loss: 0.2759\n",
      "Epoch [22/40], Step [60/100], Training Loss: 0.3130, Validation Loss: 0.2749\n",
      "Epoch [22/40], Step [70/100], Training Loss: 0.1310, Validation Loss: 0.2726\n",
      "Epoch [22/40], Step [80/100], Training Loss: 0.2400, Validation Loss: 0.2724\n",
      "Epoch [22/40], Step [90/100], Training Loss: 0.2023, Validation Loss: 0.2735\n",
      "Epoch [22/40], Step [100/100], Training Loss: 0.2832, Validation Loss: 0.2880\n",
      "Epoch [23/40], Step [10/100], Training Loss: 0.1823, Validation Loss: 0.2898\n",
      "Epoch [23/40], Step [20/100], Training Loss: 0.3227, Validation Loss: 0.2902\n",
      "Epoch [23/40], Step [30/100], Training Loss: 0.1677, Validation Loss: 0.2794\n",
      "Epoch [23/40], Step [40/100], Training Loss: 0.3276, Validation Loss: 0.2689\n",
      "Epoch [23/40], Step [50/100], Training Loss: 0.1423, Validation Loss: 0.2755\n",
      "Epoch [23/40], Step [60/100], Training Loss: 0.1972, Validation Loss: 0.2726\n",
      "Epoch [23/40], Step [70/100], Training Loss: 0.2050, Validation Loss: 0.2734\n",
      "Epoch [23/40], Step [80/100], Training Loss: 0.4417, Validation Loss: 0.2708\n",
      "Epoch [23/40], Step [90/100], Training Loss: 0.4986, Validation Loss: 0.2696\n",
      "Epoch [23/40], Step [100/100], Training Loss: 0.1555, Validation Loss: 0.2718\n",
      "Epoch [24/40], Step [10/100], Training Loss: 0.1222, Validation Loss: 0.2795\n",
      "Epoch [24/40], Step [20/100], Training Loss: 0.2719, Validation Loss: 0.2692\n",
      "Epoch [24/40], Step [30/100], Training Loss: 0.1956, Validation Loss: 0.2675\n",
      "Epoch [24/40], Step [40/100], Training Loss: 0.1541, Validation Loss: 0.2721\n",
      "Epoch [24/40], Step [50/100], Training Loss: 0.2651, Validation Loss: 0.2797\n",
      "Epoch [24/40], Step [60/100], Training Loss: 0.2072, Validation Loss: 0.2689\n",
      "Epoch [24/40], Step [70/100], Training Loss: 0.3258, Validation Loss: 0.2654\n",
      "Epoch [24/40], Step [80/100], Training Loss: 0.4021, Validation Loss: 0.2934\n",
      "Epoch [24/40], Step [90/100], Training Loss: 0.2276, Validation Loss: 0.2690\n",
      "Epoch [24/40], Step [100/100], Training Loss: 0.3042, Validation Loss: 0.2820\n",
      "Epoch [25/40], Step [10/100], Training Loss: 0.3461, Validation Loss: 0.2727\n",
      "Epoch [25/40], Step [20/100], Training Loss: 0.1227, Validation Loss: 0.2678\n",
      "Epoch [25/40], Step [30/100], Training Loss: 0.1374, Validation Loss: 0.2806\n",
      "Epoch [25/40], Step [40/100], Training Loss: 0.2034, Validation Loss: 0.2806\n",
      "Epoch [25/40], Step [50/100], Training Loss: 0.1941, Validation Loss: 0.2699\n",
      "Epoch [25/40], Step [60/100], Training Loss: 0.2789, Validation Loss: 0.2650\n",
      "Epoch [25/40], Step [70/100], Training Loss: 0.4059, Validation Loss: 0.2873\n",
      "Epoch [25/40], Step [80/100], Training Loss: 0.4203, Validation Loss: 0.2719\n",
      "Epoch [25/40], Step [90/100], Training Loss: 0.1489, Validation Loss: 0.2621\n",
      "Epoch [25/40], Step [100/100], Training Loss: 0.1464, Validation Loss: 0.2624\n",
      "Epoch [26/40], Step [10/100], Training Loss: 0.2853, Validation Loss: 0.2669\n",
      "Epoch [26/40], Step [20/100], Training Loss: 0.2831, Validation Loss: 0.2655\n",
      "Epoch [26/40], Step [30/100], Training Loss: 0.1761, Validation Loss: 0.2647\n",
      "Epoch [26/40], Step [40/100], Training Loss: 0.1833, Validation Loss: 0.2618\n",
      "Epoch [26/40], Step [50/100], Training Loss: 0.3287, Validation Loss: 0.2709\n",
      "Epoch [26/40], Step [60/100], Training Loss: 0.1623, Validation Loss: 0.2699\n",
      "Epoch [26/40], Step [70/100], Training Loss: 0.6928, Validation Loss: 0.2760\n",
      "Epoch [26/40], Step [80/100], Training Loss: 0.1916, Validation Loss: 0.2690\n",
      "Epoch [26/40], Step [90/100], Training Loss: 0.1325, Validation Loss: 0.2943\n",
      "Epoch [26/40], Step [100/100], Training Loss: 0.4722, Validation Loss: 0.2675\n",
      "Epoch [27/40], Step [10/100], Training Loss: 0.0572, Validation Loss: 0.2606\n",
      "Epoch [27/40], Step [20/100], Training Loss: 0.2369, Validation Loss: 0.2617\n",
      "Epoch [27/40], Step [30/100], Training Loss: 0.3738, Validation Loss: 0.2643\n",
      "Epoch [27/40], Step [40/100], Training Loss: 0.1532, Validation Loss: 0.2719\n",
      "Epoch [27/40], Step [50/100], Training Loss: 0.2299, Validation Loss: 0.2682\n",
      "Epoch [27/40], Step [60/100], Training Loss: 0.1615, Validation Loss: 0.2734\n",
      "Epoch [27/40], Step [70/100], Training Loss: 0.1064, Validation Loss: 0.2609\n",
      "Epoch [27/40], Step [80/100], Training Loss: 0.3413, Validation Loss: 0.2638\n",
      "Epoch [27/40], Step [90/100], Training Loss: 0.2060, Validation Loss: 0.2653\n",
      "Epoch [27/40], Step [100/100], Training Loss: 0.2212, Validation Loss: 0.2819\n",
      "Epoch [28/40], Step [10/100], Training Loss: 0.1069, Validation Loss: 0.2647\n",
      "Epoch [28/40], Step [20/100], Training Loss: 0.2153, Validation Loss: 0.2626\n",
      "Epoch [28/40], Step [30/100], Training Loss: 0.2969, Validation Loss: 0.2590\n",
      "Epoch [28/40], Step [40/100], Training Loss: 0.3212, Validation Loss: 0.2608\n",
      "Epoch [28/40], Step [50/100], Training Loss: 0.2410, Validation Loss: 0.2625\n",
      "Epoch [28/40], Step [60/100], Training Loss: 0.2295, Validation Loss: 0.2905\n",
      "Epoch [28/40], Step [70/100], Training Loss: 0.2256, Validation Loss: 0.2611\n",
      "Process stop at epoch [28/40] with patience 10 within tolerance 0.0001\n"
     ]
    }
   ],
   "source": [
    "main.train_val(num_epochs=40, interval=10, tolerance=1e-4, patience=10, early_stop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model with Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of Box on the 104 test dataset: 0.18220241367816925.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('problem', 'multi-outputs'),\n",
       "             ('loss',\n",
       "              {'train': 0.32005155086517334,\n",
       "               'val': 0.26151183247566223,\n",
       "               'test': 0.18220241367816925})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = torch.as_tensor(X, dtype=torch.float).to(torch.device(\"cuda\")), torch.as_tensor(y, dtype=torch.float).to(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = main.model(X) # predicted\n",
    "# refer to https://pytorch.org/torcheval/main/ for metrics functional tools, like classification\n",
    "# take input as pred, target as y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'75.9%'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{}%'.format(100 * sum(row.all().int().item() for row in (pred.ge(0.5) == y)) / X.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model Parameters to Models Folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.save(show=False, dir='../models/outputs.ckpt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model Parameters from Models Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.load(show=False, dir='../models/outputs.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
