{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-outputs Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install polars[pandas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas # or use `polars`\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_multilabel_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_multilabel_classification(n_samples=1000, \n",
    "                                      n_features=10,\n",
    "                                      n_classes=3,\n",
    "                                      n_labels=2,\n",
    "                                      random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 10), (1000, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Perming and Config Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (Linear0): Linear(in_features=10, out_features=30, bias=True)\n",
      "    (Activation0): ReLU(inplace=True)\n",
      "    (Linear1): Linear(in_features=30, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('torch -v', '1.7.1+cu101'),\n",
       "             ('criterion', MultiLabelSoftMarginLoss()),\n",
       "             ('batch_size', 8),\n",
       "             ('solver',\n",
       "              SGD (\n",
       "              Parameter Group 0\n",
       "                  dampening: 0\n",
       "                  lr: 0.01\n",
       "                  momentum: 0\n",
       "                  nesterov: False\n",
       "                  weight_decay: 0\n",
       "              )),\n",
       "             ('lr_scheduler', None),\n",
       "             ('device', device(type='cuda'))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import perming\n",
    "main = perming.Box(10, 3, (30,), batch_size=8, activation='relu', inplace_on=True, solver='sgd', criterion=\"MultiLabelSoftMarginLoss\", learning_rate_init=0.01)\n",
    "# main = perming.Ranker(10, 3, (30,), batch_size=16, activation='relu', solver='sgd', criterion=\"MultiLabelSoftMarginLoss\", learning_rate_init=0.01)\n",
    "# main = perming.COMMON_MODELS['Multi-outputs'](10, 3, (30,), batch_size=16, activation='relu', solver='sgd', criterion=\"MultiLabelSoftMarginLoss\", learning_rate_init=0.01)\n",
    "main.print_config()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader from Numpy with Multi-threaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.data_loader(X, y, random_seed=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Stage and Accelerated Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40], Step [10/100], Training Loss: 0.4588, Validation Loss: 0.6206\n",
      "Epoch [1/40], Step [20/100], Training Loss: 0.4977, Validation Loss: 0.5936\n",
      "Epoch [1/40], Step [30/100], Training Loss: 0.6046, Validation Loss: 0.5684\n",
      "Epoch [1/40], Step [40/100], Training Loss: 0.5572, Validation Loss: 0.5566\n",
      "Epoch [1/40], Step [50/100], Training Loss: 0.6522, Validation Loss: 0.5514\n",
      "Epoch [1/40], Step [60/100], Training Loss: 0.3386, Validation Loss: 0.5348\n",
      "Epoch [1/40], Step [70/100], Training Loss: 0.5743, Validation Loss: 0.5256\n",
      "Epoch [1/40], Step [80/100], Training Loss: 0.3826, Validation Loss: 0.5162\n",
      "Epoch [1/40], Step [90/100], Training Loss: 0.5820, Validation Loss: 0.5080\n",
      "Epoch [1/40], Step [100/100], Training Loss: 0.5111, Validation Loss: 0.5049\n",
      "Epoch [2/40], Step [10/100], Training Loss: 0.2895, Validation Loss: 0.4991\n",
      "Epoch [2/40], Step [20/100], Training Loss: 0.3002, Validation Loss: 0.4889\n",
      "Epoch [2/40], Step [30/100], Training Loss: 0.4480, Validation Loss: 0.4856\n",
      "Epoch [2/40], Step [40/100], Training Loss: 0.3342, Validation Loss: 0.4817\n",
      "Epoch [2/40], Step [50/100], Training Loss: 0.3378, Validation Loss: 0.4768\n",
      "Epoch [2/40], Step [60/100], Training Loss: 0.3679, Validation Loss: 0.4724\n",
      "Epoch [2/40], Step [70/100], Training Loss: 0.3989, Validation Loss: 0.4672\n",
      "Epoch [2/40], Step [80/100], Training Loss: 0.4656, Validation Loss: 0.4667\n",
      "Epoch [2/40], Step [90/100], Training Loss: 0.4465, Validation Loss: 0.4610\n",
      "Epoch [2/40], Step [100/100], Training Loss: 0.5580, Validation Loss: 0.4608\n",
      "Epoch [3/40], Step [10/100], Training Loss: 0.4293, Validation Loss: 0.4562\n",
      "Epoch [3/40], Step [20/100], Training Loss: 0.4358, Validation Loss: 0.4539\n",
      "Epoch [3/40], Step [30/100], Training Loss: 0.3278, Validation Loss: 0.4510\n",
      "Epoch [3/40], Step [40/100], Training Loss: 0.5240, Validation Loss: 0.4466\n",
      "Epoch [3/40], Step [50/100], Training Loss: 0.3608, Validation Loss: 0.4460\n",
      "Epoch [3/40], Step [60/100], Training Loss: 0.4276, Validation Loss: 0.4453\n",
      "Epoch [3/40], Step [70/100], Training Loss: 0.3835, Validation Loss: 0.4404\n",
      "Epoch [3/40], Step [80/100], Training Loss: 0.4560, Validation Loss: 0.4375\n",
      "Epoch [3/40], Step [90/100], Training Loss: 0.4703, Validation Loss: 0.4349\n",
      "Epoch [3/40], Step [100/100], Training Loss: 0.3929, Validation Loss: 0.4306\n",
      "Epoch [4/40], Step [10/100], Training Loss: 0.3865, Validation Loss: 0.4289\n",
      "Epoch [4/40], Step [20/100], Training Loss: 0.4448, Validation Loss: 0.4270\n",
      "Epoch [4/40], Step [30/100], Training Loss: 0.3468, Validation Loss: 0.4258\n",
      "Epoch [4/40], Step [40/100], Training Loss: 0.2881, Validation Loss: 0.4212\n",
      "Epoch [4/40], Step [50/100], Training Loss: 0.4149, Validation Loss: 0.4179\n",
      "Epoch [4/40], Step [60/100], Training Loss: 0.2695, Validation Loss: 0.4198\n",
      "Epoch [4/40], Step [70/100], Training Loss: 0.4922, Validation Loss: 0.4175\n",
      "Epoch [4/40], Step [80/100], Training Loss: 0.3966, Validation Loss: 0.4188\n",
      "Epoch [4/40], Step [90/100], Training Loss: 0.3204, Validation Loss: 0.4191\n",
      "Epoch [4/40], Step [100/100], Training Loss: 0.4056, Validation Loss: 0.4082\n",
      "Epoch [5/40], Step [10/100], Training Loss: 0.3030, Validation Loss: 0.4118\n",
      "Epoch [5/40], Step [20/100], Training Loss: 0.3392, Validation Loss: 0.4078\n",
      "Epoch [5/40], Step [30/100], Training Loss: 0.2980, Validation Loss: 0.4066\n",
      "Epoch [5/40], Step [40/100], Training Loss: 0.3010, Validation Loss: 0.4047\n",
      "Epoch [5/40], Step [50/100], Training Loss: 0.4325, Validation Loss: 0.3992\n",
      "Epoch [5/40], Step [60/100], Training Loss: 0.2619, Validation Loss: 0.3971\n",
      "Epoch [5/40], Step [70/100], Training Loss: 0.2664, Validation Loss: 0.3955\n",
      "Epoch [5/40], Step [80/100], Training Loss: 0.1988, Validation Loss: 0.3929\n",
      "Epoch [5/40], Step [90/100], Training Loss: 0.3169, Validation Loss: 0.3987\n",
      "Epoch [5/40], Step [100/100], Training Loss: 0.3617, Validation Loss: 0.3898\n",
      "Epoch [6/40], Step [10/100], Training Loss: 0.3700, Validation Loss: 0.3903\n",
      "Epoch [6/40], Step [20/100], Training Loss: 0.1767, Validation Loss: 0.3858\n",
      "Epoch [6/40], Step [30/100], Training Loss: 0.3524, Validation Loss: 0.3837\n",
      "Epoch [6/40], Step [40/100], Training Loss: 0.3511, Validation Loss: 0.3857\n",
      "Epoch [6/40], Step [50/100], Training Loss: 0.3334, Validation Loss: 0.3795\n",
      "Epoch [6/40], Step [60/100], Training Loss: 0.3790, Validation Loss: 0.3787\n",
      "Epoch [6/40], Step [70/100], Training Loss: 0.2270, Validation Loss: 0.3782\n",
      "Epoch [6/40], Step [80/100], Training Loss: 0.2547, Validation Loss: 0.3778\n",
      "Epoch [6/40], Step [90/100], Training Loss: 0.2368, Validation Loss: 0.3746\n",
      "Epoch [6/40], Step [100/100], Training Loss: 0.1715, Validation Loss: 0.3781\n",
      "Epoch [7/40], Step [10/100], Training Loss: 0.2729, Validation Loss: 0.3703\n",
      "Epoch [7/40], Step [20/100], Training Loss: 0.2368, Validation Loss: 0.3678\n",
      "Epoch [7/40], Step [30/100], Training Loss: 0.3123, Validation Loss: 0.3666\n",
      "Epoch [7/40], Step [40/100], Training Loss: 0.2988, Validation Loss: 0.3629\n",
      "Epoch [7/40], Step [50/100], Training Loss: 0.3489, Validation Loss: 0.3627\n",
      "Epoch [7/40], Step [60/100], Training Loss: 0.2016, Validation Loss: 0.3713\n",
      "Epoch [7/40], Step [70/100], Training Loss: 0.3532, Validation Loss: 0.3591\n",
      "Epoch [7/40], Step [80/100], Training Loss: 0.3624, Validation Loss: 0.3711\n",
      "Epoch [7/40], Step [90/100], Training Loss: 0.3022, Validation Loss: 0.3577\n",
      "Epoch [7/40], Step [100/100], Training Loss: 0.1885, Validation Loss: 0.3545\n",
      "Epoch [8/40], Step [10/100], Training Loss: 0.3173, Validation Loss: 0.3578\n",
      "Epoch [8/40], Step [20/100], Training Loss: 0.2929, Validation Loss: 0.3545\n",
      "Epoch [8/40], Step [30/100], Training Loss: 0.1572, Validation Loss: 0.3619\n",
      "Epoch [8/40], Step [40/100], Training Loss: 0.3410, Validation Loss: 0.3536\n",
      "Epoch [8/40], Step [50/100], Training Loss: 0.4493, Validation Loss: 0.3498\n",
      "Epoch [8/40], Step [60/100], Training Loss: 0.2317, Validation Loss: 0.3486\n",
      "Epoch [8/40], Step [70/100], Training Loss: 0.2127, Validation Loss: 0.3478\n",
      "Epoch [8/40], Step [80/100], Training Loss: 0.3208, Validation Loss: 0.3429\n",
      "Epoch [8/40], Step [90/100], Training Loss: 0.4675, Validation Loss: 0.3442\n",
      "Epoch [8/40], Step [100/100], Training Loss: 0.3228, Validation Loss: 0.3478\n",
      "Epoch [9/40], Step [10/100], Training Loss: 0.1434, Validation Loss: 0.3366\n",
      "Epoch [9/40], Step [20/100], Training Loss: 0.2861, Validation Loss: 0.3369\n",
      "Epoch [9/40], Step [30/100], Training Loss: 0.4577, Validation Loss: 0.3350\n",
      "Epoch [9/40], Step [40/100], Training Loss: 0.3740, Validation Loss: 0.3355\n",
      "Epoch [9/40], Step [50/100], Training Loss: 0.1542, Validation Loss: 0.3293\n",
      "Epoch [9/40], Step [60/100], Training Loss: 0.4332, Validation Loss: 0.3280\n",
      "Epoch [9/40], Step [70/100], Training Loss: 0.3380, Validation Loss: 0.3321\n",
      "Epoch [9/40], Step [80/100], Training Loss: 0.2651, Validation Loss: 0.3260\n",
      "Epoch [9/40], Step [90/100], Training Loss: 0.2692, Validation Loss: 0.3314\n",
      "Epoch [9/40], Step [100/100], Training Loss: 0.3857, Validation Loss: 0.3245\n",
      "Epoch [10/40], Step [10/100], Training Loss: 0.3067, Validation Loss: 0.3227\n",
      "Epoch [10/40], Step [20/100], Training Loss: 0.2415, Validation Loss: 0.3231\n",
      "Epoch [10/40], Step [30/100], Training Loss: 0.3510, Validation Loss: 0.3254\n",
      "Epoch [10/40], Step [40/100], Training Loss: 0.2141, Validation Loss: 0.3252\n",
      "Epoch [10/40], Step [50/100], Training Loss: 0.1659, Validation Loss: 0.3183\n",
      "Epoch [10/40], Step [60/100], Training Loss: 0.3894, Validation Loss: 0.3144\n",
      "Epoch [10/40], Step [70/100], Training Loss: 0.2859, Validation Loss: 0.3215\n",
      "Epoch [10/40], Step [80/100], Training Loss: 0.3127, Validation Loss: 0.3144\n",
      "Epoch [10/40], Step [90/100], Training Loss: 0.2035, Validation Loss: 0.3137\n",
      "Epoch [10/40], Step [100/100], Training Loss: 0.2053, Validation Loss: 0.3124\n",
      "Epoch [11/40], Step [10/100], Training Loss: 0.2585, Validation Loss: 0.3086\n",
      "Epoch [11/40], Step [20/100], Training Loss: 0.2216, Validation Loss: 0.3144\n",
      "Epoch [11/40], Step [30/100], Training Loss: 0.2440, Validation Loss: 0.3221\n",
      "Epoch [11/40], Step [40/100], Training Loss: 0.2874, Validation Loss: 0.3116\n",
      "Epoch [11/40], Step [50/100], Training Loss: 0.4518, Validation Loss: 0.3081\n",
      "Epoch [11/40], Step [60/100], Training Loss: 0.3785, Validation Loss: 0.3038\n",
      "Epoch [11/40], Step [70/100], Training Loss: 0.2636, Validation Loss: 0.3058\n",
      "Epoch [11/40], Step [80/100], Training Loss: 0.2632, Validation Loss: 0.3016\n",
      "Epoch [11/40], Step [90/100], Training Loss: 0.4330, Validation Loss: 0.3012\n",
      "Epoch [11/40], Step [100/100], Training Loss: 0.2358, Validation Loss: 0.3075\n",
      "Epoch [12/40], Step [10/100], Training Loss: 0.4199, Validation Loss: 0.3009\n",
      "Epoch [12/40], Step [20/100], Training Loss: 0.2301, Validation Loss: 0.3133\n",
      "Epoch [12/40], Step [30/100], Training Loss: 0.3426, Validation Loss: 0.3049\n",
      "Epoch [12/40], Step [40/100], Training Loss: 0.5697, Validation Loss: 0.3149\n",
      "Epoch [12/40], Step [50/100], Training Loss: 0.4385, Validation Loss: 0.3067\n",
      "Epoch [12/40], Step [60/100], Training Loss: 0.1893, Validation Loss: 0.2941\n",
      "Epoch [12/40], Step [70/100], Training Loss: 0.1581, Validation Loss: 0.2927\n",
      "Epoch [12/40], Step [80/100], Training Loss: 0.3322, Validation Loss: 0.2923\n",
      "Epoch [12/40], Step [90/100], Training Loss: 0.1805, Validation Loss: 0.2995\n",
      "Epoch [12/40], Step [100/100], Training Loss: 0.2151, Validation Loss: 0.2923\n",
      "Epoch [13/40], Step [10/100], Training Loss: 0.3036, Validation Loss: 0.2917\n",
      "Epoch [13/40], Step [20/100], Training Loss: 0.1596, Validation Loss: 0.3045\n",
      "Epoch [13/40], Step [30/100], Training Loss: 0.2396, Validation Loss: 0.2866\n",
      "Process stop at epoch [13/40] with patience 10 within tolerance 0.0001\n"
     ]
    }
   ],
   "source": [
    "main.train_val(num_epochs=40, interval=10, tolerance=1e-4, patience=10, early_stop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model with Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of Box on the 104 test dataset: 0.20897558331489563. accuracy: 0.0000 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('problem', 'multi-outputs'),\n",
       "             ('loss',\n",
       "              {'train': 0.21326859295368195,\n",
       "               'val': 0.2859066426753998,\n",
       "               'test': 0.20897558331489563})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = torch.as_tensor(X, dtype=torch.float).to(torch.device(\"cuda\")), torch.as_tensor(y, dtype=torch.float).to(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = main.model(X) # predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'72.8%'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{}%'.format(100 * sum(row.all().int().item() for row in (pred.ge(0.5) == y)) / X.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model Parameters to Models Folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.save(show=False, dir='../models/outputs.ckpt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model Parameters from Models Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.load(show=False, dir='../models/outputs.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
