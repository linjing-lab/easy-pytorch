{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-outputs Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install polars[pandas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas # or use `polars`\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_multilabel_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_multilabel_classification(n_samples=1000, \n",
    "                                      n_features=10,\n",
    "                                      n_classes=3,\n",
    "                                      n_labels=2,\n",
    "                                      random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 10), (1000, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Perming and Config Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (Linear0): Linear(in_features=10, out_features=30, bias=True)\n",
      "    (Activation0): ReLU(inplace=True)\n",
      "    (Linear1): Linear(in_features=30, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('torch -v', '1.7.1+cu101'),\n",
       "             ('criterion', MultiLabelSoftMarginLoss()),\n",
       "             ('batch_size', 8),\n",
       "             ('solver',\n",
       "              SGD (\n",
       "              Parameter Group 0\n",
       "                  dampening: 0\n",
       "                  lr: 0.01\n",
       "                  momentum: 0\n",
       "                  nesterov: False\n",
       "                  weight_decay: 0\n",
       "              )),\n",
       "             ('lr_scheduler', None),\n",
       "             ('device', device(type='cuda'))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import perming\n",
    "main = perming.Box(10, 3, (30,), batch_size=8, activation='relu', inplace_on=True, solver='sgd', criterion=\"MultiLabelSoftMarginLoss\", learning_rate_init=0.01)\n",
    "# main = perming.Ranker(10, 3, (30,), batch_size=16, activation='relu', solver='sgd', criterion=\"MultiLabelSoftMarginLoss\", learning_rate_init=0.01)\n",
    "# main = perming.COMMON_MODELS['Multi-outputs'](10, 3, (30,), batch_size=16, activation='relu', solver='sgd', criterion=\"MultiLabelSoftMarginLoss\", learning_rate_init=0.01)\n",
    "main.print_config()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader from Numpy with Multi-threaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.data_loader(X, y, random_seed=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Stage and Accelerated Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40], Step [10/100], Training Loss: 0.6327, Validation Loss: 0.6009\n",
      "Epoch [1/40], Step [20/100], Training Loss: 0.6511, Validation Loss: 0.5789\n",
      "Epoch [1/40], Step [30/100], Training Loss: 0.5905, Validation Loss: 0.5667\n",
      "Epoch [1/40], Step [40/100], Training Loss: 0.4751, Validation Loss: 0.5532\n",
      "Epoch [1/40], Step [50/100], Training Loss: 0.4320, Validation Loss: 0.5498\n",
      "Epoch [1/40], Step [60/100], Training Loss: 0.6378, Validation Loss: 0.5371\n",
      "Epoch [1/40], Step [70/100], Training Loss: 0.5327, Validation Loss: 0.5276\n",
      "Epoch [1/40], Step [80/100], Training Loss: 0.5670, Validation Loss: 0.5186\n",
      "Epoch [1/40], Step [90/100], Training Loss: 0.4096, Validation Loss: 0.5050\n",
      "Epoch [1/40], Step [100/100], Training Loss: 0.5404, Validation Loss: 0.4920\n",
      "Epoch [2/40], Step [10/100], Training Loss: 0.4262, Validation Loss: 0.4892\n",
      "Epoch [2/40], Step [20/100], Training Loss: 0.4222, Validation Loss: 0.4801\n",
      "Epoch [2/40], Step [30/100], Training Loss: 0.4579, Validation Loss: 0.4745\n",
      "Epoch [2/40], Step [40/100], Training Loss: 0.4922, Validation Loss: 0.4658\n",
      "Epoch [2/40], Step [50/100], Training Loss: 0.2764, Validation Loss: 0.4628\n",
      "Epoch [2/40], Step [60/100], Training Loss: 0.3612, Validation Loss: 0.4522\n",
      "Epoch [2/40], Step [70/100], Training Loss: 0.3346, Validation Loss: 0.4471\n",
      "Epoch [2/40], Step [80/100], Training Loss: 0.4354, Validation Loss: 0.4421\n",
      "Epoch [2/40], Step [90/100], Training Loss: 0.5408, Validation Loss: 0.4414\n",
      "Epoch [2/40], Step [100/100], Training Loss: 0.5009, Validation Loss: 0.4384\n",
      "Epoch [3/40], Step [10/100], Training Loss: 0.4424, Validation Loss: 0.4293\n",
      "Epoch [3/40], Step [20/100], Training Loss: 0.5491, Validation Loss: 0.4224\n",
      "Epoch [3/40], Step [30/100], Training Loss: 0.3700, Validation Loss: 0.4200\n",
      "Epoch [3/40], Step [40/100], Training Loss: 0.3288, Validation Loss: 0.4157\n",
      "Epoch [3/40], Step [50/100], Training Loss: 0.2047, Validation Loss: 0.4147\n",
      "Epoch [3/40], Step [60/100], Training Loss: 0.4474, Validation Loss: 0.4096\n",
      "Epoch [3/40], Step [70/100], Training Loss: 0.3629, Validation Loss: 0.4090\n",
      "Epoch [3/40], Step [80/100], Training Loss: 0.4073, Validation Loss: 0.4048\n",
      "Epoch [3/40], Step [90/100], Training Loss: 0.3927, Validation Loss: 0.4016\n",
      "Epoch [3/40], Step [100/100], Training Loss: 0.3638, Validation Loss: 0.4006\n",
      "Epoch [4/40], Step [10/100], Training Loss: 0.3054, Validation Loss: 0.3932\n",
      "Epoch [4/40], Step [20/100], Training Loss: 0.4391, Validation Loss: 0.3957\n",
      "Epoch [4/40], Step [30/100], Training Loss: 0.3818, Validation Loss: 0.3903\n",
      "Epoch [4/40], Step [40/100], Training Loss: 0.3389, Validation Loss: 0.3883\n",
      "Epoch [4/40], Step [50/100], Training Loss: 0.5642, Validation Loss: 0.3857\n",
      "Epoch [4/40], Step [60/100], Training Loss: 0.3122, Validation Loss: 0.3835\n",
      "Epoch [4/40], Step [70/100], Training Loss: 0.2799, Validation Loss: 0.3843\n",
      "Epoch [4/40], Step [80/100], Training Loss: 0.2833, Validation Loss: 0.3753\n",
      "Epoch [4/40], Step [90/100], Training Loss: 0.3754, Validation Loss: 0.3771\n",
      "Epoch [4/40], Step [100/100], Training Loss: 0.3424, Validation Loss: 0.3730\n",
      "Epoch [5/40], Step [10/100], Training Loss: 0.2691, Validation Loss: 0.3725\n",
      "Epoch [5/40], Step [20/100], Training Loss: 0.3075, Validation Loss: 0.3653\n",
      "Epoch [5/40], Step [30/100], Training Loss: 0.2728, Validation Loss: 0.3653\n",
      "Epoch [5/40], Step [40/100], Training Loss: 0.4341, Validation Loss: 0.3661\n",
      "Epoch [5/40], Step [50/100], Training Loss: 0.3769, Validation Loss: 0.3690\n",
      "Epoch [5/40], Step [60/100], Training Loss: 0.2365, Validation Loss: 0.3629\n",
      "Epoch [5/40], Step [70/100], Training Loss: 0.2277, Validation Loss: 0.3647\n",
      "Epoch [5/40], Step [80/100], Training Loss: 0.4799, Validation Loss: 0.3579\n",
      "Epoch [5/40], Step [90/100], Training Loss: 0.3658, Validation Loss: 0.3553\n",
      "Epoch [5/40], Step [100/100], Training Loss: 0.2586, Validation Loss: 0.3517\n",
      "Epoch [6/40], Step [10/100], Training Loss: 0.5486, Validation Loss: 0.3508\n",
      "Epoch [6/40], Step [20/100], Training Loss: 0.3466, Validation Loss: 0.3496\n",
      "Epoch [6/40], Step [30/100], Training Loss: 0.2507, Validation Loss: 0.3525\n",
      "Epoch [6/40], Step [40/100], Training Loss: 0.2319, Validation Loss: 0.3505\n",
      "Epoch [6/40], Step [50/100], Training Loss: 0.2923, Validation Loss: 0.3470\n",
      "Epoch [6/40], Step [60/100], Training Loss: 0.1695, Validation Loss: 0.3486\n",
      "Epoch [6/40], Step [70/100], Training Loss: 0.2699, Validation Loss: 0.3404\n",
      "Epoch [6/40], Step [80/100], Training Loss: 0.1728, Validation Loss: 0.3392\n",
      "Epoch [6/40], Step [90/100], Training Loss: 0.1163, Validation Loss: 0.3415\n",
      "Epoch [6/40], Step [100/100], Training Loss: 0.4915, Validation Loss: 0.3417\n",
      "Epoch [7/40], Step [10/100], Training Loss: 0.1988, Validation Loss: 0.3356\n",
      "Epoch [7/40], Step [20/100], Training Loss: 0.3485, Validation Loss: 0.3368\n",
      "Epoch [7/40], Step [30/100], Training Loss: 0.3528, Validation Loss: 0.3362\n",
      "Epoch [7/40], Step [40/100], Training Loss: 0.3831, Validation Loss: 0.3328\n",
      "Epoch [7/40], Step [50/100], Training Loss: 0.3362, Validation Loss: 0.3374\n",
      "Epoch [7/40], Step [60/100], Training Loss: 0.2438, Validation Loss: 0.3322\n",
      "Epoch [7/40], Step [70/100], Training Loss: 0.3728, Validation Loss: 0.3361\n",
      "Epoch [7/40], Step [80/100], Training Loss: 0.2628, Validation Loss: 0.3299\n",
      "Epoch [7/40], Step [90/100], Training Loss: 0.2424, Validation Loss: 0.3323\n",
      "Epoch [7/40], Step [100/100], Training Loss: 0.2744, Validation Loss: 0.3283\n",
      "Epoch [8/40], Step [10/100], Training Loss: 0.3262, Validation Loss: 0.3241\n",
      "Epoch [8/40], Step [20/100], Training Loss: 0.1786, Validation Loss: 0.3233\n",
      "Epoch [8/40], Step [30/100], Training Loss: 0.1855, Validation Loss: 0.3259\n",
      "Epoch [8/40], Step [40/100], Training Loss: 0.2724, Validation Loss: 0.3209\n",
      "Epoch [8/40], Step [50/100], Training Loss: 0.4002, Validation Loss: 0.3196\n",
      "Epoch [8/40], Step [60/100], Training Loss: 0.4612, Validation Loss: 0.3253\n",
      "Epoch [8/40], Step [70/100], Training Loss: 0.1633, Validation Loss: 0.3197\n",
      "Epoch [8/40], Step [80/100], Training Loss: 0.1997, Validation Loss: 0.3233\n",
      "Epoch [8/40], Step [90/100], Training Loss: 0.3801, Validation Loss: 0.3304\n",
      "Epoch [8/40], Step [100/100], Training Loss: 0.3379, Validation Loss: 0.3414\n",
      "Epoch [9/40], Step [10/100], Training Loss: 0.2171, Validation Loss: 0.3222\n",
      "Epoch [9/40], Step [20/100], Training Loss: 0.3114, Validation Loss: 0.3182\n",
      "Epoch [9/40], Step [30/100], Training Loss: 0.1712, Validation Loss: 0.3205\n",
      "Epoch [9/40], Step [40/100], Training Loss: 0.3464, Validation Loss: 0.3149\n",
      "Epoch [9/40], Step [50/100], Training Loss: 0.2119, Validation Loss: 0.3242\n",
      "Epoch [9/40], Step [60/100], Training Loss: 0.3243, Validation Loss: 0.3209\n",
      "Epoch [9/40], Step [70/100], Training Loss: 0.1936, Validation Loss: 0.3162\n",
      "Epoch [9/40], Step [80/100], Training Loss: 0.1049, Validation Loss: 0.3199\n",
      "Epoch [9/40], Step [90/100], Training Loss: 0.4430, Validation Loss: 0.3118\n",
      "Epoch [9/40], Step [100/100], Training Loss: 0.2806, Validation Loss: 0.3126\n",
      "Epoch [10/40], Step [10/100], Training Loss: 0.2818, Validation Loss: 0.3141\n",
      "Epoch [10/40], Step [20/100], Training Loss: 0.1321, Validation Loss: 0.3123\n",
      "Epoch [10/40], Step [30/100], Training Loss: 0.3384, Validation Loss: 0.3145\n",
      "Epoch [10/40], Step [40/100], Training Loss: 0.3279, Validation Loss: 0.3095\n",
      "Epoch [10/40], Step [50/100], Training Loss: 0.2720, Validation Loss: 0.3090\n",
      "Epoch [10/40], Step [60/100], Training Loss: 0.3086, Validation Loss: 0.3103\n",
      "Epoch [10/40], Step [70/100], Training Loss: 0.3541, Validation Loss: 0.3090\n",
      "Epoch [10/40], Step [80/100], Training Loss: 0.4774, Validation Loss: 0.3294\n",
      "Epoch [10/40], Step [90/100], Training Loss: 0.1918, Validation Loss: 0.3225\n",
      "Epoch [10/40], Step [100/100], Training Loss: 0.1846, Validation Loss: 0.3094\n",
      "Epoch [11/40], Step [10/100], Training Loss: 0.2997, Validation Loss: 0.3048\n",
      "Epoch [11/40], Step [20/100], Training Loss: 0.1800, Validation Loss: 0.3087\n",
      "Epoch [11/40], Step [30/100], Training Loss: 0.3384, Validation Loss: 0.3062\n",
      "Epoch [11/40], Step [40/100], Training Loss: 0.1959, Validation Loss: 0.3063\n",
      "Epoch [11/40], Step [50/100], Training Loss: 0.2486, Validation Loss: 0.3076\n",
      "Epoch [11/40], Step [60/100], Training Loss: 0.2344, Validation Loss: 0.3107\n",
      "Epoch [11/40], Step [70/100], Training Loss: 0.4931, Validation Loss: 0.3240\n",
      "Epoch [11/40], Step [80/100], Training Loss: 0.4419, Validation Loss: 0.3037\n",
      "Epoch [11/40], Step [90/100], Training Loss: 0.1215, Validation Loss: 0.3123\n",
      "Epoch [11/40], Step [100/100], Training Loss: 0.3584, Validation Loss: 0.3118\n",
      "Epoch [12/40], Step [10/100], Training Loss: 0.2969, Validation Loss: 0.3109\n",
      "Epoch [12/40], Step [20/100], Training Loss: 0.4815, Validation Loss: 0.3037\n",
      "Epoch [12/40], Step [30/100], Training Loss: 0.2174, Validation Loss: 0.3047\n",
      "Epoch [12/40], Step [40/100], Training Loss: 0.2384, Validation Loss: 0.3091\n",
      "Epoch [12/40], Step [50/100], Training Loss: 0.1528, Validation Loss: 0.3005\n",
      "Epoch [12/40], Step [60/100], Training Loss: 0.3494, Validation Loss: 0.3026\n",
      "Epoch [12/40], Step [70/100], Training Loss: 0.3696, Validation Loss: 0.3077\n",
      "Epoch [12/40], Step [80/100], Training Loss: 0.1582, Validation Loss: 0.3007\n",
      "Epoch [12/40], Step [90/100], Training Loss: 0.4401, Validation Loss: 0.2962\n",
      "Epoch [12/40], Step [100/100], Training Loss: 0.3797, Validation Loss: 0.3074\n",
      "Epoch [13/40], Step [10/100], Training Loss: 0.1394, Validation Loss: 0.2990\n",
      "Epoch [13/40], Step [20/100], Training Loss: 0.1990, Validation Loss: 0.3000\n",
      "Epoch [13/40], Step [30/100], Training Loss: 0.3172, Validation Loss: 0.3022\n",
      "Epoch [13/40], Step [40/100], Training Loss: 0.3115, Validation Loss: 0.2956\n",
      "Epoch [13/40], Step [50/100], Training Loss: 0.2545, Validation Loss: 0.2956\n",
      "Epoch [13/40], Step [60/100], Training Loss: 0.4275, Validation Loss: 0.3004\n",
      "Epoch [13/40], Step [70/100], Training Loss: 0.1272, Validation Loss: 0.2949\n",
      "Epoch [13/40], Step [80/100], Training Loss: 0.3900, Validation Loss: 0.3000\n",
      "Epoch [13/40], Step [90/100], Training Loss: 0.3396, Validation Loss: 0.2985\n",
      "Epoch [13/40], Step [100/100], Training Loss: 0.2051, Validation Loss: 0.2967\n",
      "Epoch [14/40], Step [10/100], Training Loss: 0.2662, Validation Loss: 0.3062\n",
      "Epoch [14/40], Step [20/100], Training Loss: 0.1500, Validation Loss: 0.2924\n",
      "Epoch [14/40], Step [30/100], Training Loss: 0.2382, Validation Loss: 0.3079\n",
      "Epoch [14/40], Step [40/100], Training Loss: 0.1940, Validation Loss: 0.3033\n",
      "Epoch [14/40], Step [50/100], Training Loss: 0.3889, Validation Loss: 0.2932\n",
      "Epoch [14/40], Step [60/100], Training Loss: 0.1884, Validation Loss: 0.2941\n",
      "Epoch [14/40], Step [70/100], Training Loss: 0.1579, Validation Loss: 0.2980\n",
      "Epoch [14/40], Step [80/100], Training Loss: 0.3917, Validation Loss: 0.2982\n",
      "Epoch [14/40], Step [90/100], Training Loss: 0.2000, Validation Loss: 0.2973\n",
      "Epoch [14/40], Step [100/100], Training Loss: 0.1388, Validation Loss: 0.3105\n",
      "Epoch [15/40], Step [10/100], Training Loss: 0.2847, Validation Loss: 0.3136\n",
      "Epoch [15/40], Step [20/100], Training Loss: 0.2379, Validation Loss: 0.2921\n",
      "Epoch [15/40], Step [30/100], Training Loss: 0.2077, Validation Loss: 0.2997\n",
      "Epoch [15/40], Step [40/100], Training Loss: 0.5489, Validation Loss: 0.3025\n",
      "Epoch [15/40], Step [50/100], Training Loss: 0.3561, Validation Loss: 0.2886\n",
      "Epoch [15/40], Step [60/100], Training Loss: 0.3049, Validation Loss: 0.2907\n",
      "Epoch [15/40], Step [70/100], Training Loss: 0.2362, Validation Loss: 0.3057\n",
      "Epoch [15/40], Step [80/100], Training Loss: 0.1748, Validation Loss: 0.2899\n",
      "Epoch [15/40], Step [90/100], Training Loss: 0.1275, Validation Loss: 0.2879\n",
      "Epoch [15/40], Step [100/100], Training Loss: 0.2279, Validation Loss: 0.2869\n",
      "Epoch [16/40], Step [10/100], Training Loss: 0.2550, Validation Loss: 0.2836\n",
      "Epoch [16/40], Step [20/100], Training Loss: 0.2126, Validation Loss: 0.2859\n",
      "Epoch [16/40], Step [30/100], Training Loss: 0.2302, Validation Loss: 0.2906\n",
      "Epoch [16/40], Step [40/100], Training Loss: 0.3361, Validation Loss: 0.2888\n",
      "Epoch [16/40], Step [50/100], Training Loss: 0.0898, Validation Loss: 0.2900\n",
      "Epoch [16/40], Step [60/100], Training Loss: 0.1412, Validation Loss: 0.2870\n",
      "Epoch [16/40], Step [70/100], Training Loss: 0.3724, Validation Loss: 0.2890\n",
      "Epoch [16/40], Step [80/100], Training Loss: 0.3587, Validation Loss: 0.2911\n",
      "Epoch [16/40], Step [90/100], Training Loss: 0.1592, Validation Loss: 0.2869\n",
      "Epoch [16/40], Step [100/100], Training Loss: 0.3001, Validation Loss: 0.3069\n",
      "Epoch [17/40], Step [10/100], Training Loss: 0.3119, Validation Loss: 0.2887\n",
      "Epoch [17/40], Step [20/100], Training Loss: 0.1107, Validation Loss: 0.3008\n",
      "Epoch [17/40], Step [30/100], Training Loss: 0.1915, Validation Loss: 0.2887\n",
      "Epoch [17/40], Step [40/100], Training Loss: 0.2875, Validation Loss: 0.2853\n",
      "Epoch [17/40], Step [50/100], Training Loss: 0.2668, Validation Loss: 0.2881\n",
      "Epoch [17/40], Step [60/100], Training Loss: 0.2188, Validation Loss: 0.2886\n",
      "Epoch [17/40], Step [70/100], Training Loss: 0.3249, Validation Loss: 0.2834\n",
      "Epoch [17/40], Step [80/100], Training Loss: 0.1199, Validation Loss: 0.2853\n",
      "Epoch [17/40], Step [90/100], Training Loss: 0.3253, Validation Loss: 0.2904\n",
      "Epoch [17/40], Step [100/100], Training Loss: 0.2880, Validation Loss: 0.2885\n",
      "Epoch [18/40], Step [10/100], Training Loss: 0.3916, Validation Loss: 0.2907\n",
      "Epoch [18/40], Step [20/100], Training Loss: 0.3136, Validation Loss: 0.2810\n",
      "Epoch [18/40], Step [30/100], Training Loss: 0.4230, Validation Loss: 0.2991\n",
      "Epoch [18/40], Step [40/100], Training Loss: 0.2347, Validation Loss: 0.2778\n",
      "Epoch [18/40], Step [50/100], Training Loss: 0.1628, Validation Loss: 0.2770\n",
      "Epoch [18/40], Step [60/100], Training Loss: 0.2241, Validation Loss: 0.2830\n",
      "Epoch [18/40], Step [70/100], Training Loss: 0.1227, Validation Loss: 0.2799\n",
      "Epoch [18/40], Step [80/100], Training Loss: 0.1835, Validation Loss: 0.2914\n",
      "Epoch [18/40], Step [90/100], Training Loss: 0.2403, Validation Loss: 0.2818\n",
      "Epoch [18/40], Step [100/100], Training Loss: 0.3092, Validation Loss: 0.2793\n",
      "Epoch [19/40], Step [10/100], Training Loss: 0.2284, Validation Loss: 0.2840\n",
      "Epoch [19/40], Step [20/100], Training Loss: 0.1668, Validation Loss: 0.3053\n",
      "Epoch [19/40], Step [30/100], Training Loss: 0.1585, Validation Loss: 0.2818\n",
      "Epoch [19/40], Step [40/100], Training Loss: 0.1351, Validation Loss: 0.2769\n",
      "Epoch [19/40], Step [50/100], Training Loss: 0.2734, Validation Loss: 0.2741\n",
      "Epoch [19/40], Step [60/100], Training Loss: 0.1663, Validation Loss: 0.2823\n",
      "Epoch [19/40], Step [70/100], Training Loss: 0.2595, Validation Loss: 0.2775\n",
      "Epoch [19/40], Step [80/100], Training Loss: 0.1584, Validation Loss: 0.2785\n",
      "Epoch [19/40], Step [90/100], Training Loss: 0.4233, Validation Loss: 0.2771\n",
      "Epoch [19/40], Step [100/100], Training Loss: 0.3137, Validation Loss: 0.2734\n",
      "Epoch [20/40], Step [10/100], Training Loss: 0.2501, Validation Loss: 0.2862\n",
      "Epoch [20/40], Step [20/100], Training Loss: 0.1331, Validation Loss: 0.2842\n",
      "Epoch [20/40], Step [30/100], Training Loss: 0.1774, Validation Loss: 0.2751\n",
      "Epoch [20/40], Step [40/100], Training Loss: 0.2933, Validation Loss: 0.2730\n",
      "Epoch [20/40], Step [50/100], Training Loss: 0.1002, Validation Loss: 0.2870\n",
      "Epoch [20/40], Step [60/100], Training Loss: 0.2213, Validation Loss: 0.2814\n",
      "Epoch [20/40], Step [70/100], Training Loss: 0.3323, Validation Loss: 0.2738\n",
      "Epoch [20/40], Step [80/100], Training Loss: 0.1537, Validation Loss: 0.2760\n",
      "Epoch [20/40], Step [90/100], Training Loss: 0.0924, Validation Loss: 0.2793\n",
      "Epoch [20/40], Step [100/100], Training Loss: 0.4160, Validation Loss: 0.2718\n",
      "Epoch [21/40], Step [10/100], Training Loss: 0.1789, Validation Loss: 0.2735\n",
      "Epoch [21/40], Step [20/100], Training Loss: 0.1897, Validation Loss: 0.2726\n",
      "Epoch [21/40], Step [30/100], Training Loss: 0.1037, Validation Loss: 0.2751\n",
      "Epoch [21/40], Step [40/100], Training Loss: 0.1826, Validation Loss: 0.2730\n",
      "Epoch [21/40], Step [50/100], Training Loss: 0.1295, Validation Loss: 0.2707\n",
      "Epoch [21/40], Step [60/100], Training Loss: 0.2543, Validation Loss: 0.2685\n",
      "Epoch [21/40], Step [70/100], Training Loss: 0.2624, Validation Loss: 0.2712\n",
      "Epoch [21/40], Step [80/100], Training Loss: 0.2718, Validation Loss: 0.2834\n",
      "Epoch [21/40], Step [90/100], Training Loss: 0.1656, Validation Loss: 0.2665\n",
      "Epoch [21/40], Step [100/100], Training Loss: 0.3708, Validation Loss: 0.2899\n",
      "Epoch [22/40], Step [10/100], Training Loss: 0.3720, Validation Loss: 0.2914\n",
      "Epoch [22/40], Step [20/100], Training Loss: 0.2018, Validation Loss: 0.2920\n",
      "Epoch [22/40], Step [30/100], Training Loss: 0.1396, Validation Loss: 0.2719\n",
      "Epoch [22/40], Step [40/100], Training Loss: 0.2068, Validation Loss: 0.2685\n",
      "Epoch [22/40], Step [50/100], Training Loss: 0.4178, Validation Loss: 0.2677\n",
      "Epoch [22/40], Step [60/100], Training Loss: 0.2702, Validation Loss: 0.2723\n",
      "Epoch [22/40], Step [70/100], Training Loss: 0.2526, Validation Loss: 0.2767\n",
      "Epoch [22/40], Step [80/100], Training Loss: 0.1499, Validation Loss: 0.2689\n",
      "Epoch [22/40], Step [90/100], Training Loss: 0.2497, Validation Loss: 0.2851\n",
      "Epoch [22/40], Step [100/100], Training Loss: 0.2425, Validation Loss: 0.2640\n",
      "Epoch [23/40], Step [10/100], Training Loss: 0.2056, Validation Loss: 0.2654\n",
      "Epoch [23/40], Step [20/100], Training Loss: 0.1450, Validation Loss: 0.2838\n",
      "Epoch [23/40], Step [30/100], Training Loss: 0.2569, Validation Loss: 0.2858\n",
      "Epoch [23/40], Step [40/100], Training Loss: 0.1260, Validation Loss: 0.2815\n",
      "Epoch [23/40], Step [50/100], Training Loss: 0.3082, Validation Loss: 0.2642\n",
      "Epoch [23/40], Step [60/100], Training Loss: 0.1556, Validation Loss: 0.2683\n",
      "Epoch [23/40], Step [70/100], Training Loss: 0.2725, Validation Loss: 0.2615\n",
      "Epoch [23/40], Step [80/100], Training Loss: 0.3407, Validation Loss: 0.2647\n",
      "Epoch [23/40], Step [90/100], Training Loss: 0.3390, Validation Loss: 0.2688\n",
      "Epoch [23/40], Step [100/100], Training Loss: 0.2520, Validation Loss: 0.2616\n",
      "Epoch [24/40], Step [10/100], Training Loss: 0.1384, Validation Loss: 0.2779\n",
      "Epoch [24/40], Step [20/100], Training Loss: 0.2515, Validation Loss: 0.2612\n",
      "Epoch [24/40], Step [30/100], Training Loss: 0.1993, Validation Loss: 0.2640\n",
      "Epoch [24/40], Step [40/100], Training Loss: 0.2569, Validation Loss: 0.2709\n",
      "Epoch [24/40], Step [50/100], Training Loss: 0.1910, Validation Loss: 0.2846\n",
      "Epoch [24/40], Step [60/100], Training Loss: 0.2236, Validation Loss: 0.2686\n",
      "Epoch [24/40], Step [70/100], Training Loss: 0.1609, Validation Loss: 0.2706\n",
      "Epoch [24/40], Step [80/100], Training Loss: 0.2303, Validation Loss: 0.2606\n",
      "Epoch [24/40], Step [90/100], Training Loss: 0.0966, Validation Loss: 0.2644\n",
      "Epoch [24/40], Step [100/100], Training Loss: 0.2464, Validation Loss: 0.2619\n",
      "Epoch [25/40], Step [10/100], Training Loss: 0.3938, Validation Loss: 0.2632\n",
      "Epoch [25/40], Step [20/100], Training Loss: 0.1870, Validation Loss: 0.2624\n",
      "Epoch [25/40], Step [30/100], Training Loss: 0.0890, Validation Loss: 0.2561\n",
      "Epoch [25/40], Step [40/100], Training Loss: 0.1666, Validation Loss: 0.2570\n",
      "Epoch [25/40], Step [50/100], Training Loss: 0.1939, Validation Loss: 0.2625\n",
      "Epoch [25/40], Step [60/100], Training Loss: 0.2228, Validation Loss: 0.2557\n",
      "Epoch [25/40], Step [70/100], Training Loss: 0.3022, Validation Loss: 0.2551\n",
      "Epoch [25/40], Step [80/100], Training Loss: 0.4192, Validation Loss: 0.2573\n",
      "Epoch [25/40], Step [90/100], Training Loss: 0.1251, Validation Loss: 0.2666\n",
      "Epoch [25/40], Step [100/100], Training Loss: 0.4325, Validation Loss: 0.2592\n",
      "Epoch [26/40], Step [10/100], Training Loss: 0.1195, Validation Loss: 0.2542\n",
      "Epoch [26/40], Step [20/100], Training Loss: 0.3414, Validation Loss: 0.2822\n",
      "Epoch [26/40], Step [30/100], Training Loss: 0.0708, Validation Loss: 0.2541\n",
      "Epoch [26/40], Step [40/100], Training Loss: 0.2664, Validation Loss: 0.2680\n",
      "Epoch [26/40], Step [50/100], Training Loss: 0.3004, Validation Loss: 0.2608\n",
      "Epoch [26/40], Step [60/100], Training Loss: 0.3546, Validation Loss: 0.2627\n",
      "Epoch [26/40], Step [70/100], Training Loss: 0.3053, Validation Loss: 0.2626\n",
      "Epoch [26/40], Step [80/100], Training Loss: 0.3984, Validation Loss: 0.2582\n",
      "Epoch [26/40], Step [90/100], Training Loss: 0.2127, Validation Loss: 0.2526\n",
      "Epoch [26/40], Step [100/100], Training Loss: 0.2913, Validation Loss: 0.2549\n",
      "Epoch [27/40], Step [10/100], Training Loss: 0.4384, Validation Loss: 0.2505\n",
      "Epoch [27/40], Step [20/100], Training Loss: 0.2209, Validation Loss: 0.2664\n",
      "Epoch [27/40], Step [30/100], Training Loss: 0.2802, Validation Loss: 0.2734\n",
      "Epoch [27/40], Step [40/100], Training Loss: 0.1882, Validation Loss: 0.2626\n",
      "Epoch [27/40], Step [50/100], Training Loss: 0.0816, Validation Loss: 0.2559\n",
      "Epoch [27/40], Step [60/100], Training Loss: 0.2368, Validation Loss: 0.2479\n",
      "Epoch [27/40], Step [70/100], Training Loss: 0.2826, Validation Loss: 0.2494\n",
      "Epoch [27/40], Step [80/100], Training Loss: 0.2290, Validation Loss: 0.2732\n",
      "Epoch [27/40], Step [90/100], Training Loss: 0.3001, Validation Loss: 0.2813\n",
      "Epoch [27/40], Step [100/100], Training Loss: 0.3178, Validation Loss: 0.2519\n",
      "Epoch [28/40], Step [10/100], Training Loss: 0.2960, Validation Loss: 0.2567\n",
      "Epoch [28/40], Step [20/100], Training Loss: 0.1805, Validation Loss: 0.2566\n",
      "Epoch [28/40], Step [30/100], Training Loss: 0.1173, Validation Loss: 0.2596\n",
      "Epoch [28/40], Step [40/100], Training Loss: 0.1701, Validation Loss: 0.2519\n",
      "Epoch [28/40], Step [50/100], Training Loss: 0.3712, Validation Loss: 0.2565\n",
      "Epoch [28/40], Step [60/100], Training Loss: 0.1424, Validation Loss: 0.2480\n",
      "Epoch [28/40], Step [70/100], Training Loss: 0.2247, Validation Loss: 0.2542\n",
      "Epoch [28/40], Step [80/100], Training Loss: 0.2501, Validation Loss: 0.2597\n",
      "Epoch [28/40], Step [90/100], Training Loss: 0.2361, Validation Loss: 0.2670\n",
      "Epoch [28/40], Step [100/100], Training Loss: 0.1913, Validation Loss: 0.2476\n",
      "Epoch [29/40], Step [10/100], Training Loss: 0.3666, Validation Loss: 0.2446\n",
      "Epoch [29/40], Step [20/100], Training Loss: 0.2301, Validation Loss: 0.2589\n",
      "Epoch [29/40], Step [30/100], Training Loss: 0.1853, Validation Loss: 0.2458\n",
      "Epoch [29/40], Step [40/100], Training Loss: 0.3161, Validation Loss: 0.2498\n",
      "Epoch [29/40], Step [50/100], Training Loss: 0.1447, Validation Loss: 0.2546\n",
      "Epoch [29/40], Step [60/100], Training Loss: 0.1955, Validation Loss: 0.2689\n",
      "Epoch [29/40], Step [70/100], Training Loss: 0.2326, Validation Loss: 0.2459\n",
      "Epoch [29/40], Step [80/100], Training Loss: 0.1875, Validation Loss: 0.2476\n",
      "Epoch [29/40], Step [90/100], Training Loss: 0.0750, Validation Loss: 0.2486\n",
      "Epoch [29/40], Step [100/100], Training Loss: 0.2887, Validation Loss: 0.2515\n",
      "Epoch [30/40], Step [10/100], Training Loss: 0.2649, Validation Loss: 0.2464\n",
      "Epoch [30/40], Step [20/100], Training Loss: 0.2160, Validation Loss: 0.2639\n",
      "Epoch [30/40], Step [30/100], Training Loss: 0.0424, Validation Loss: 0.2445\n",
      "Epoch [30/40], Step [40/100], Training Loss: 0.1252, Validation Loss: 0.2628\n",
      "Epoch [30/40], Step [50/100], Training Loss: 0.1782, Validation Loss: 0.2382\n",
      "Epoch [30/40], Step [60/100], Training Loss: 0.2891, Validation Loss: 0.2478\n",
      "Epoch [30/40], Step [70/100], Training Loss: 0.5018, Validation Loss: 0.2607\n",
      "Epoch [30/40], Step [80/100], Training Loss: 0.1688, Validation Loss: 0.2507\n",
      "Epoch [30/40], Step [90/100], Training Loss: 0.1004, Validation Loss: 0.2434\n",
      "Epoch [30/40], Step [100/100], Training Loss: 0.3200, Validation Loss: 0.2520\n",
      "Epoch [31/40], Step [10/100], Training Loss: 0.2045, Validation Loss: 0.2454\n",
      "Epoch [31/40], Step [20/100], Training Loss: 0.2500, Validation Loss: 0.2554\n",
      "Epoch [31/40], Step [30/100], Training Loss: 0.2914, Validation Loss: 0.2571\n",
      "Epoch [31/40], Step [40/100], Training Loss: 0.2731, Validation Loss: 0.2472\n",
      "Epoch [31/40], Step [50/100], Training Loss: 0.2850, Validation Loss: 0.2681\n",
      "Epoch [31/40], Step [60/100], Training Loss: 0.2318, Validation Loss: 0.2571\n",
      "Epoch [31/40], Step [70/100], Training Loss: 0.2050, Validation Loss: 0.2585\n",
      "Epoch [31/40], Step [80/100], Training Loss: 0.1972, Validation Loss: 0.2405\n",
      "Epoch [31/40], Step [90/100], Training Loss: 0.2250, Validation Loss: 0.2445\n",
      "Epoch [31/40], Step [100/100], Training Loss: 0.4539, Validation Loss: 0.2368\n",
      "Epoch [32/40], Step [10/100], Training Loss: 0.5201, Validation Loss: 0.2481\n",
      "Epoch [32/40], Step [20/100], Training Loss: 0.0394, Validation Loss: 0.2555\n",
      "Epoch [32/40], Step [30/100], Training Loss: 0.1374, Validation Loss: 0.2453\n",
      "Epoch [32/40], Step [40/100], Training Loss: 0.1734, Validation Loss: 0.2467\n",
      "Epoch [32/40], Step [50/100], Training Loss: 0.1582, Validation Loss: 0.2491\n",
      "Epoch [32/40], Step [60/100], Training Loss: 0.1576, Validation Loss: 0.2358\n",
      "Epoch [32/40], Step [70/100], Training Loss: 0.6783, Validation Loss: 0.2448\n",
      "Epoch [32/40], Step [80/100], Training Loss: 0.0546, Validation Loss: 0.2384\n",
      "Epoch [32/40], Step [90/100], Training Loss: 0.2638, Validation Loss: 0.2374\n",
      "Epoch [32/40], Step [100/100], Training Loss: 0.0536, Validation Loss: 0.2553\n",
      "Epoch [33/40], Step [10/100], Training Loss: 0.0891, Validation Loss: 0.2570\n",
      "Epoch [33/40], Step [20/100], Training Loss: 0.1200, Validation Loss: 0.2407\n",
      "Epoch [33/40], Step [30/100], Training Loss: 0.1515, Validation Loss: 0.2382\n",
      "Epoch [33/40], Step [40/100], Training Loss: 0.1695, Validation Loss: 0.2398\n",
      "Epoch [33/40], Step [50/100], Training Loss: 0.3507, Validation Loss: 0.2481\n",
      "Epoch [33/40], Step [60/100], Training Loss: 0.0917, Validation Loss: 0.2509\n",
      "Epoch [33/40], Step [70/100], Training Loss: 0.2363, Validation Loss: 0.2415\n",
      "Epoch [33/40], Step [80/100], Training Loss: 0.1349, Validation Loss: 0.2457\n",
      "Epoch [33/40], Step [90/100], Training Loss: 0.2938, Validation Loss: 0.2355\n",
      "Epoch [33/40], Step [100/100], Training Loss: 0.5251, Validation Loss: 0.2409\n",
      "Epoch [34/40], Step [10/100], Training Loss: 0.3063, Validation Loss: 0.2327\n",
      "Epoch [34/40], Step [20/100], Training Loss: 0.3220, Validation Loss: 0.2334\n",
      "Epoch [34/40], Step [30/100], Training Loss: 0.1775, Validation Loss: 0.2413\n",
      "Epoch [34/40], Step [40/100], Training Loss: 0.2678, Validation Loss: 0.2371\n",
      "Epoch [34/40], Step [50/100], Training Loss: 0.2416, Validation Loss: 0.2524\n",
      "Epoch [34/40], Step [60/100], Training Loss: 0.2345, Validation Loss: 0.2483\n",
      "Epoch [34/40], Step [70/100], Training Loss: 0.1990, Validation Loss: 0.2387\n",
      "Epoch [34/40], Step [80/100], Training Loss: 0.1828, Validation Loss: 0.2312\n",
      "Epoch [34/40], Step [90/100], Training Loss: 0.0430, Validation Loss: 0.2356\n",
      "Epoch [34/40], Step [100/100], Training Loss: 0.0702, Validation Loss: 0.2590\n",
      "Epoch [35/40], Step [10/100], Training Loss: 0.0688, Validation Loss: 0.2682\n",
      "Epoch [35/40], Step [20/100], Training Loss: 0.2486, Validation Loss: 0.2483\n",
      "Epoch [35/40], Step [30/100], Training Loss: 0.2730, Validation Loss: 0.2481\n",
      "Epoch [35/40], Step [40/100], Training Loss: 0.1668, Validation Loss: 0.2562\n",
      "Epoch [35/40], Step [50/100], Training Loss: 0.3965, Validation Loss: 0.2353\n",
      "Epoch [35/40], Step [60/100], Training Loss: 0.1840, Validation Loss: 0.2293\n",
      "Epoch [35/40], Step [70/100], Training Loss: 0.1174, Validation Loss: 0.2301\n",
      "Epoch [35/40], Step [80/100], Training Loss: 0.2774, Validation Loss: 0.2464\n",
      "Epoch [35/40], Step [90/100], Training Loss: 0.3305, Validation Loss: 0.2261\n",
      "Epoch [35/40], Step [100/100], Training Loss: 0.4348, Validation Loss: 0.2340\n",
      "Epoch [36/40], Step [10/100], Training Loss: 0.1229, Validation Loss: 0.2391\n",
      "Epoch [36/40], Step [20/100], Training Loss: 0.2281, Validation Loss: 0.2566\n",
      "Epoch [36/40], Step [30/100], Training Loss: 0.3237, Validation Loss: 0.2439\n",
      "Epoch [36/40], Step [40/100], Training Loss: 0.0733, Validation Loss: 0.2346\n",
      "Epoch [36/40], Step [50/100], Training Loss: 0.0864, Validation Loss: 0.2458\n",
      "Epoch [36/40], Step [60/100], Training Loss: 0.1125, Validation Loss: 0.2306\n",
      "Epoch [36/40], Step [70/100], Training Loss: 0.1338, Validation Loss: 0.2385\n",
      "Epoch [36/40], Step [80/100], Training Loss: 0.1608, Validation Loss: 0.2333\n",
      "Epoch [36/40], Step [90/100], Training Loss: 0.1919, Validation Loss: 0.2572\n",
      "Epoch [36/40], Step [100/100], Training Loss: 0.2385, Validation Loss: 0.2326\n",
      "Epoch [37/40], Step [10/100], Training Loss: 0.0426, Validation Loss: 0.2535\n",
      "Epoch [37/40], Step [20/100], Training Loss: 0.2659, Validation Loss: 0.2405\n",
      "Epoch [37/40], Step [30/100], Training Loss: 0.3342, Validation Loss: 0.2314\n",
      "Epoch [37/40], Step [40/100], Training Loss: 0.1937, Validation Loss: 0.2317\n",
      "Epoch [37/40], Step [50/100], Training Loss: 0.2070, Validation Loss: 0.2299\n",
      "Epoch [37/40], Step [60/100], Training Loss: 0.1777, Validation Loss: 0.2269\n",
      "Epoch [37/40], Step [70/100], Training Loss: 0.3554, Validation Loss: 0.2304\n",
      "Epoch [37/40], Step [80/100], Training Loss: 0.2140, Validation Loss: 0.2276\n",
      "Epoch [37/40], Step [90/100], Training Loss: 0.0985, Validation Loss: 0.2386\n",
      "Epoch [37/40], Step [100/100], Training Loss: 0.1839, Validation Loss: 0.2293\n",
      "Epoch [38/40], Step [10/100], Training Loss: 0.1152, Validation Loss: 0.2255\n",
      "Epoch [38/40], Step [20/100], Training Loss: 0.0789, Validation Loss: 0.2427\n",
      "Epoch [38/40], Step [30/100], Training Loss: 0.1581, Validation Loss: 0.2310\n",
      "Epoch [38/40], Step [40/100], Training Loss: 0.1988, Validation Loss: 0.2381\n",
      "Epoch [38/40], Step [50/100], Training Loss: 0.1372, Validation Loss: 0.2344\n",
      "Epoch [38/40], Step [60/100], Training Loss: 0.1338, Validation Loss: 0.2334\n",
      "Epoch [38/40], Step [70/100], Training Loss: 0.2621, Validation Loss: 0.2317\n",
      "Epoch [38/40], Step [80/100], Training Loss: 0.1419, Validation Loss: 0.2224\n",
      "Epoch [38/40], Step [90/100], Training Loss: 0.2430, Validation Loss: 0.2478\n",
      "Epoch [38/40], Step [100/100], Training Loss: 0.1213, Validation Loss: 0.2367\n",
      "Epoch [39/40], Step [10/100], Training Loss: 0.2580, Validation Loss: 0.2394\n",
      "Epoch [39/40], Step [20/100], Training Loss: 0.1020, Validation Loss: 0.2269\n",
      "Epoch [39/40], Step [30/100], Training Loss: 0.1578, Validation Loss: 0.2285\n",
      "Epoch [39/40], Step [40/100], Training Loss: 0.1748, Validation Loss: 0.2387\n",
      "Epoch [39/40], Step [50/100], Training Loss: 0.1625, Validation Loss: 0.2369\n",
      "Epoch [39/40], Step [60/100], Training Loss: 0.0825, Validation Loss: 0.2536\n",
      "Epoch [39/40], Step [70/100], Training Loss: 0.1311, Validation Loss: 0.2537\n",
      "Epoch [39/40], Step [80/100], Training Loss: 0.1175, Validation Loss: 0.2244\n",
      "Epoch [39/40], Step [90/100], Training Loss: 0.3484, Validation Loss: 0.2189\n",
      "Epoch [39/40], Step [100/100], Training Loss: 0.1401, Validation Loss: 0.2315\n",
      "Epoch [40/40], Step [10/100], Training Loss: 0.2606, Validation Loss: 0.2275\n",
      "Epoch [40/40], Step [20/100], Training Loss: 0.0707, Validation Loss: 0.2274\n",
      "Epoch [40/40], Step [30/100], Training Loss: 0.2489, Validation Loss: 0.2430\n",
      "Epoch [40/40], Step [40/100], Training Loss: 0.2487, Validation Loss: 0.2223\n",
      "Epoch [40/40], Step [50/100], Training Loss: 0.1694, Validation Loss: 0.2521\n",
      "Epoch [40/40], Step [60/100], Training Loss: 0.0817, Validation Loss: 0.2276\n",
      "Epoch [40/40], Step [70/100], Training Loss: 0.2937, Validation Loss: 0.2364\n",
      "Epoch [40/40], Step [80/100], Training Loss: 0.2348, Validation Loss: 0.2285\n",
      "Epoch [40/40], Step [90/100], Training Loss: 0.0780, Validation Loss: 0.2284\n",
      "Epoch [40/40], Step [100/100], Training Loss: 0.1129, Validation Loss: 0.2246\n"
     ]
    }
   ],
   "source": [
    "main.train_val(num_epochs=40, interval=10, tolerance=1e-4, patience=10, early_stop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model with Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of Box on the 104 test dataset: 0.1438077986240387.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('problem', 'multi-outputs'),\n",
       "             ('loss',\n",
       "              {'train': 0.11292307078838348,\n",
       "               'val': 0.2245670109987259,\n",
       "               'test': 0.1438077986240387})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = torch.as_tensor(X, dtype=torch.float).to(torch.device(\"cuda\")), torch.as_tensor(y, dtype=torch.float).to(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = main.model(X) # predicted\n",
    "# refer to https://pytorch.org/torcheval/main/ for metrics functional tools, like classification\n",
    "# take input as pred, target as y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'81.2%'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{}%'.format(100 * sum(row.all().int().item() for row in (pred.ge(0.5) == y)) / X.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model Parameters to Models Folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.save(show=False, dir='../models/outputs.ckpt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model Parameters from Models Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.load(show=False, dir='../models/outputs.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
